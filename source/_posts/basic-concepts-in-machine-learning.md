---
title: 机器学习基础
date: 2018-05-28 13:36:00
updated: 2018-05-28 15:43:51
tags: Deep Learning
mathjax: true
---

## 前言

DeepLearning.ai 第二部分内容是改善深层神经网络，主要包括超参数的调试、正则化以及优化。这些内容大部分都是机器学习的基础，深度学习是机器学习的一个特定分支，要想充分理解深度学习就必须对机器学习的基本原理有深刻的理解。

<!-- more -->

## 训练/验证/测试集

 当训练神经网络的时候，我们需要做出很多决策，例如神经网络要分多少层、隐藏层有多少个神经元、学习率是多少、每一层用什么激活函数等等。当创建一个新的应用的时候，我们不可能一开始就准确地预测出这些信息和其他超参数。所以应用型机器学习是一个高度迭代地过程：有个想法，然后写代码实现，分析实验结果，再改进自己的想法，然后写代码实现...创建高质量的训练集(Train set)、验证集(Development set)和测试集(Test set)有助于提高迭代效率。

在小数据量时代，常见的作法是将数据三七分(70% 训练集，30% “测试”集)或者 60%/20%/20% 划分训练集、验证集和测试集。在大数据时代，训练集的比重可能会更大，例如有一百万条数据，验证集和测试集可能只需要一万条数据，即 98%/1%/1% 。值得注意的是，验证集和测试集应该是同分布的，在测试集上评估的是验证集选出的模型；但是为了获取更大规模的训练集，训练集的分布可以和验证集/测试集不同分布。

## 超参数

大多机器学习算法都有超参数(例如上面需要做的决策)来控制算法行为，不同的超参数表示不同的模型。超参数的值**不是**通过算法本身学习出来(即使可以设计一个嵌套的学习过程学出最优超参数)。有时一个选项被设为超参数是因为它太难优化了，例如代价函数并不能给出**学习率**的更新方向，很难优化学习率；更多的情况是该选项必须是超参数，因为它不适合在训练集上学习，例如在**训练集**上学习控制模型容量的超参数，这些超参数总是趋向于最大可能的模型容量，导致过拟合。例如 M 次多项式拟合中，更倾向于在训练集上学出次数最高的模型，虽然训练误差小，但是拟合了噪声会导致过拟合，在遇到新数据的时候泛化误差就会很大。

超参数优化或模型选择是为了优化算法在**独立数据集**上的性能的度量 ，通常使用**验证集**进行交叉验证来**估计这种泛化性能**，指导超参数的调节。和训练数据相同分布的样本组成的测试集用来估计学习器的泛化误差，其重点在于测试样本不能以任何形式参与到模型的选择中 (包括设定超参数)。基于这个原因，测试集中的样本不能用于验证集，因此总是从训练数据中构建验证集。

深度学习中的超参数根据其重要性排序，大概有以下几个：

* <font color="red">学习率 $\alpha$ </font>
* <font color="orange">Momentum 参数 $\beta$ (默认值：0.9)</font>
* <font color="orange">隐藏神经元数 #hidden units</font>
* <font color="orange">小批量的大小 mini-batch size</font>
* <font color="purple">神经网络层数 #layers</font>
* <font color="purple">学习率衰减</font>
* <font color="blue">Adam 算法参数 $\beta_1, \beta_2, \varepsilon$ (默认值：$0.9, 0.999, 10^{-8}$)</font>

### 超参数的调节

调节参数一般选择网格搜索的方法，但是推荐在网格中随机选择点，因为可能某个参数的某些取值不重要；另一个惯例是采用由粗糙到精细的策略，因为某个点效果好的话，也许这个点周围的其他一些点效果也很好。其次要为超参数选择合适的范围，而且对于某些超参数，不应该在取值范围内随机均匀取值，例如学习率 $\alpha$ 用对数标尺搜索超参数的方式会更合理，因此这里不使用线性轴，分别依次取 $0.0001, 0.001, 0.01, 0.1, 1$。

超参数的调节主要有两种方法：

1. 一次试验一个模型，将超参数随机初始化，然后观察模型的学习曲线(例如代价函数曲线)，根据学习曲线慢慢调节超参数
2. 同时试验多种模型，最后快速选择工作效果最好的那个

在机器学习中，如果只有一个训练集和一个验证集，验证集则被人们称为“测试”集，不过人们只是把测试集当成简单交叉验证集使用，即评估模型的泛化能力，然后调节模型的超参数，所以“训练验证集“在专业用词上更准确。

因此，训练集用来训练模型，调节参数；验证集用来调节超参数，选择模型；尽管验证集的误差通常比训练集误差小，但是验证集会低估泛化误差，完成超参数优化后，还需要测试集来估计泛化误差。如果验证集具有足够泛化性，那么就不需要测试集来给出泛化误差的无偏估计。

## 偏差/方差

假设有数据集 $x=\{x_1, x_2, …, x_n\}$，并且真实标签 $y_i$ 对应数据点 $x_i$。假设函数 $y=f(x)+\epsilon$ ，其中噪声 $\epsilon$ 为 0 均值的高斯分布，方差为 $\sigma^2$，表示数据集与标签并不是完全符合函数 $y$。我们希望通过机器学习找到 $\hat f(x)$，通过最小化均方误差 $(y-\hat f(x))^2$，尽可能地逼近 $f(x)$。由于样本数据具有噪声，所以 $\hat f(x)$ 不会完全拟合 $y$。<font color="red">误差</font>定义为：
$$
\begin{align}
Err(x)&=E\left[(y-\hat f(x))\right]^2 \\\
&= \left(E[\hat f(x)]-f(x)\right)^2+E\left[\Big(\hat f(x)-E[\hat f(x)]\Big)^2\right]+\sigma^2 \\\
&= \text{Bias}^2+\text{Variance}+\text{Irreducible Error}
\end{align}
$$
对于训练误差，由于训练数据已知，即输入输出不是变量，常量的期望等于它本身，所以偏差 $\text{Bias}=\hat f(x)-f(x)$，度量着偏离真实函数或参数的误差；方差 $\text{Variance}=\Big(\hat f(x)-\hat f(x)\Big)^2=0$。表示训练误差由偏差和随机误差构成。

对于泛化误差，偏差 $\text{Bias}=E[\hat f(x)]-f(x)$ 度量着偏离真实函数或参数的误差期望；方差 $\text{Variance}=E\left[\Big(\hat f(x)-E[\hat f(x)]\Big)^2\right]$ 度量着数据上任意特定采样可能导致的估计期望的偏差(方差大，则对于不同采样，估计期望不一样)；噪声的方差为随机误差。一般说偏差、方差都是针对泛化来说的：

<img src="https://s1.ax2x.com/2018/05/29/7TrKl.png" style="width:400px">

因为验证集和训练集是同分布随机采样，所以 $E[\hat f(x)]=\hat f(x)$，即泛化误差的偏差的平方等于训练误差(泛化误差=训练误差+方差)。在机器学习中，我们不仅希望降低训练误差(避免欠拟合)，也希望缩小训练误差和泛化误差的差距(避免过拟合)，这样就能缩小泛化误差。

### 欠拟合/过拟合

假设 $y=f(x)+\epsilon=sin(2\pi x)+\epsilon, x \in [0, 1]$ (“<font color="#00FF00">---</font>” 表示)，根据已有数据 (“<font color="blue">o</font>” 表示)，我们只能猜测它是一个 M 多项式 (“<font color="red">---</font>” 表示)。

![](https://s1.ax2x.com/2018/05/29/7Xd26.png)

M = 0, 1 则欠拟合，因为模型不能在训练集上获得足够低的误差，所以偏差比较大。对于 M = 0，$\hat f(x)=c$ **泛化误差**为：
$$
\begin{align}
Err(x)&=E\left[(y-\hat f(x))\right]^2 \\\
&= \left(E[\hat f(x)]-f(x)\right)^2+E\left[\Big(\hat f(x)-E[\hat f(x)]\Big)^2\right]+\sigma^2 \\\
&= \Big(c-f(x)\Big)^2+E\Big[\Big(c-E[c]\Big)^2\Big]+\sigma^2 \\\
&= \Big(c-f(x)\Big)^2+0+\sigma^2
\end{align}
$$
所以欠拟合会导致偏差大；而 M = 9 则过拟合，因为它同时拟合了噪声，所以对于 $[0, 1]$ 中未知的数据，训练误差和泛化误差之间的差距很大，方差比较大。对于 M = 9 预测模型输出的期望为样本的期望，即：
$$
E[\hat f(x)]=E[y(x)]=E[f(x)+\epsilon]=f(x)=E[y]
$$
**泛化误差**为：
$$
\begin{align}
Err(x)&=E\left[(y-\hat f(x))\right]^2 \\\
&= \left(E[\hat f(x)]-f(x)\right)^2+E\left[\Big(\hat f(x)-E[\hat f(x)]\Big)^2\right]+\sigma^2 \\\
&= \Big(E[y]-E[y]\Big)^2+E\left[\Big(\hat f(x)-E[y]\Big)^2\right]+\sigma^2 \\\
&= 0+E\Big[\Big(E[y]+\epsilon-E[y]\Big)^2\Big]+\sigma^2 \\\
&= 0+E[\epsilon^2]+\sigma^2
\end{align}
$$
所以过拟合会导致方差大；M = 3 就是一个比较合适的模型，偏差和方差权衡得比较好。模型泛化误差、偏差、方差和模型的复杂度的关系如下图所示，模型越复杂越能拟合训练数据，所以偏差越小，但是由于拟合了噪声越多，所以遇到新数据时，泛化能力越弱，方差越大：

![](https://s1.ax2x.com/2018/05/29/7XLt9.png)

模型的训练误差、泛化误差和模型的复杂度的关系如下图所示：

![](https://s1.ax2x.com/2018/05/29/7msSR.jpg)

对于偏差和方差的分析要基于最优误差(贝叶斯误差)，即对于一个问题，如果机器学习算法的偏差为 10%，而人类分析的误差为 15%，那么就不能说该算法的偏差高。假设人类错误率为 0%，且训练误差和验证误差如下表所示，则有：

|                 |                |                |                |                |
| --------------- | -------------- | -------------- | -------------- | -------------- |
| Train set error | 1%             | 15%            | 15%            | 0.5%           |
| Dev set error   | 11%            | 16%            | 30%            | 1%             |
|                 | 高方差(低偏差) | 高偏差(低方差) | 高偏差，高方差 | 低偏差，低方差 |
|                 | 过拟合         | 欠拟合         | 欠拟合         | Good           |


遇到高偏差，可以考虑添加多一些数据特征、使用复杂一点的模型或者调低正则项的惩罚因数；遇到高方差，可以考虑使用更多的训练数据、更少的数据特征或者调高正则项的惩罚因数。总之就是不断调整模型，不断尝试，直到找到一个比较合适的模型，能够较好地均衡偏差和方差。

### 无偏估计

估计的偏差被定义为：
$$
\text{bias}(\hat{\boldsymbol{\theta}}_m) = E(\hat{\boldsymbol{\theta}}_m) − \boldsymbol{\theta}
$$
如果 $\text{bias}(\hat{\boldsymbol{\theta}}_m) = 0$，那么估计量 $\hat{\boldsymbol{\theta}}_m$ 被称为是**无偏** (unbiased)，这意味着 $E(\hat{\boldsymbol{\theta}}_m) = \boldsymbol{\theta}$。无偏估计表示没有系统上的误差，估算的结果的期望值等于真实值，产生误差的原因只可能是随机因素。例如高斯分布的样本均值就是高斯均值参数的无偏估计：
$$
\begin{align}
\text{bias}(\hat{\mu}_m) &= E[\hat{\mu}\_m] - \mu \\\
& = E\Big[\frac{1}{m}\sum\limits_{i = 0}^{m}x^{(i)}\Big] - \mu \\\
&= \frac{1}{m}\sum_{i=1}^m E[x^{(i)}] - \mu \\\
&= \frac{1}{m}\sum_{i=1}^m\mu - \mu \\\
&= 0
\end{align}
$$
高斯分布的**样本方差**是有偏估计：
$$
\begin{align}
\text{bias}(\hat{\sigma}_m^2) &= E[\hat{\sigma}\_m^2] - \sigma^2 \\\
&= E\Big[\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\hat{\mu}\_m)^2\Big] - \sigma^2 \\\
&= \frac{1}{m}E\Big[\sum_{i=1}^m(x^{(i)}-\mu+\mu-\hat{\mu}\_m)^2\Big] - \sigma^2 \\\
&= \frac{1}{m}E\Big[\sum_{i=1}^m(x^{(i)}-\mu)^2-2\sum_{i=1}^m(x^{(i)}-\mu)(\hat{\mu}\_m-\mu)+m(\hat{\mu}\_m-\mu)^2\Big] - \sigma^2 \\\
&= \frac{1}{m}\Big[\sum_{i=1}^mE(x^{(i)}-\mu)^2-2mE(\hat{\mu}\_m-\mu)^2+mE(\hat{\mu}\_m-\mu)^2\Big] - \sigma^2 \\\
&= \frac{1}{m}\Big[m\sigma^2-mE(\hat{\mu}\_m-\mu)^2\Big] - \sigma^2 \\\
&= E[\hat{\mu}\_m-\mu]^2
\end{align}
$$
其中：
$$
\begin{align}
E[\hat{\mu}\_m-\mu]^2 &= E\Big[\hat{\mu}\_m-E[\hat{\mu}\_m]\Big]^2 \\\
&= Var(\hat{\mu}\_m) \\\
&= Var(\frac{\sum_{i=1}^mx^{(i)}}{m}) \\\
&= \frac{1}{m^2}\sum_{i=1}^mVar(x^{(i)}) \\\
&= -\frac{m\sigma^2}{m^2} \\\
&= -\frac{\sigma^2}{m}
\end{align}
$$
高斯分布的无偏样本方差估计(m 个样本，m-1 个自由度，因为总体期望未知，用**样本均值**代替了总体期望，所以少了一个自由度)：
$$
\tilde{\sigma}\_m^2 = \frac{1}{m}\sum_{i=1}^m (x^{(i)}-\mu)^2 = \frac{1}{m-1}\sum_{i=1}^m (x^{(i)}-\hat{\mu}_m)^2
$$

## 参考文献

[1] 吴恩达. DeepLearning. 

[2] Ian Goodfellow, Yoshua Bengio, Aaron Courville. Deep Learning. 人民邮电出版社. 2017.

[3] 机器学习笔记. https://feisky.xyz/machine-learning

[4] Christopher M.Bishop. Pattern Recognition and Machine Learning. 2006.