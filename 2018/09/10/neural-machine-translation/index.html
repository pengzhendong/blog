<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"pengzhendong.github.io",root:"/",scheme:"Pisces",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!0,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{appID:"0C48U14D5U",apiKey:"796da148bd60fa95ebae037cae6d5c16",indexName:"Notes",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!1,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="前言 将人类可读的日期格式翻译成机器可读的日期格式，这个想法真的很有意思。这篇博客记录了如何使用 attention 机制来进行机器翻译。"><meta property="og:type" content="article"><meta property="og:title" content="自然机器翻译"><meta property="og:url" content="https://pengzhendong.github.io/2018/09/10/neural-machine-translation/index.html"><meta property="og:site_name" content="Randy&#39;s Notes"><meta property="og:description" content="前言 将人类可读的日期格式翻译成机器可读的日期格式，这个想法真的很有意思。这篇博客记录了如何使用 attention 机制来进行机器翻译。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://pengzhendong.github.io/2018/09/10/neural-machine-translation/attn_model.png"><meta property="og:image" content="https://pengzhendong.github.io/2018/09/10/neural-machine-translation/attn_mechanism.png"><meta property="og:image" content="https://pengzhendong.github.io/2018/09/10/neural-machine-translation/output.png"><meta property="article:published_time" content="2018-09-10T13:47:00.000Z"><meta property="article:modified_time" content="2018-09-10T15:27:23.000Z"><meta property="article:author" content="Randy Peng"><meta property="article:tag" content="Deep Learning"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://pengzhendong.github.io/2018/09/10/neural-machine-translation/attn_model.png"><link rel="canonical" href="https://pengzhendong.github.io/2018/09/10/neural-machine-translation/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><style type="text/css">body{background-image:url(/images/rockywall.png)}</style><title>自然机器翻译 | Randy's Notes</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-92548519-1"></script><script>if(CONFIG.hostname===location.hostname){function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-92548519-1")}</script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?06c54470f22c395ef480d6fb358497d5";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><style>mjx-container[jax=SVG]{direction:ltr}mjx-container[jax=SVG]>svg{overflow:visible}mjx-container[jax=SVG][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=SVG][justify=left]{text-align:left}mjx-container[jax=SVG][justify=right]{text-align:right}g[data-mml-node=merror]>g{fill:red;stroke:red}g[data-mml-node=merror]>rect[data-background]{fill:#ff0;stroke:none}g[data-mml-node=mtable]>line[data-line]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>rect[data-frame]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>.mjx-dashed{stroke-dasharray:140}g[data-mml-node=mtable]>.mjx-dotted{stroke-linecap:round;stroke-dasharray:0,140}g[data-mml-node=mtable]>svg{overflow:visible}[jax=SVG] mjx-tool{display:inline-block;position:relative;width:0;height:0}[jax=SVG] mjx-tool>mjx-tip{position:absolute;top:0;left:0}mjx-tool>mjx-tip{display:inline-block;padding:.2em;border:1px solid #888;font-size:70%;background-color:#f8f8f8;color:#000;box-shadow:2px 2px 5px #aaa}g[data-mml-node=maction][data-toggle]{cursor:pointer}mjx-status{display:block;position:fixed;left:1em;bottom:1em;min-width:25%;padding:.2em .4em;border:1px solid #888;font-size:90%;background-color:#f8f8f8;color:#000}foreignObject[data-mjx-xml]{font-family:initial;line-height:normal;overflow:visible}.MathJax path{stroke-width:3}mjx-container[display=true]{overflow:auto hidden}mjx-container[display=true]+br{display:none}</style></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">Randy's Notes</h1><span class="logo-line-after"><i></i></span></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档</a></li><li class="menu-item menu-item-友链"><a href="/friends/" rel="section"><i class="fa fa-users fa-fw"></i> 友链</a></li><li class="menu-item menu-item-书单"><a href="/books/" rel="section"><i class="fa fa-book fa-fw"></i> 书单</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div class="algolia-results"><div id="algolia-stats"></div><div id="algolia-hits"></div><div id="algolia-pagination" class="algolia-pagination"></div></div></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><a href="https://github.com/pengzhendong" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://pengzhendong.github.io/2018/09/10/neural-machine-translation/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Randy Peng"><meta itemprop="description" content="路漫漫其修远兮 吾将上下而求索"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Randy's Notes"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">自然机器翻译</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2018-09-10 13:47:00 / 修改时间：15:27:23" itemprop="dateCreated datePublished" datetime="2018-09-10T13:47:00+00:00">2018-09-10</time></span><span id="/2018/09/10/neural-machine-translation/" class="post-meta-item leancloud_visitors" data-flag-title="自然机器翻译" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span class="leancloud-visitors-count"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>5.5k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>5 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="前言">前言</h2><p>将人类可读的日期格式翻译成机器可读的日期格式，这个想法真的很有意思。这篇博客记录了如何使用 attention 机制来进行机器翻译。</p><span id="more"></span><h2 id="数据集">数据集</h2><p>首先来看一下数据集，即人类和机器可读的日期格式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">m = <span class="number">10000</span></span><br><span class="line">dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)</span><br><span class="line">dataset[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[('9 may 1998', '1998-05-09'),</span><br><span class="line"> ('10.09.70', '1970-09-10'),</span><br><span class="line"> ('4/28/90', '1990-04-28'),</span><br><span class="line"> ('thursday january 26 1995', '1995-01-26'),</span><br><span class="line"> ('monday march 7 1983', '1983-03-07'),</span><br><span class="line"> ('sunday may 22 1988', '1988-05-22'),</span><br><span class="line"> ('tuesday july 8 2008', '2008-07-08'),</span><br><span class="line"> ('08 sep 1999', '1999-09-08'),</span><br><span class="line"> ('1 jan 1981', '1981-01-01'),</span><br><span class="line"> ('monday may 22 1995', '1995-05-22')]</span><br></pre></td></tr></table></figure><p>二元组的第一个元素是人类可读的日期格式，第二个是对应的机器可读的日期格式。假设人可读日期格式的最大长度为 30，机器的为 10，数据处理如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Tx = <span class="number">30</span></span><br><span class="line">Ty = <span class="number">10</span></span><br><span class="line">X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)</span><br></pre></td></tr></table></figure><ul><li>X.shape: (10000, 30)</li><li>Y.shape: (10000, 10)</li><li>Xoh.shape: (10000, 30, 37)</li><li>Yoh.shape: (10000, 10, 11)</li></ul><p>一共有 10000 个样本，将样本以字符级别变成独热向量。人类可读的日期格式包含 26 个字母、10 个数字和 1 个分隔符；机器可读的日期格式包含 10 个数字和 1 个分割符。</p><h2 id="attention-机制">Attention 机制</h2><p>Attention 机制如下图左图所示；右图为一个 attention 步，计算的 attention 变量<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.025ex" xmlns="http://www.w3.org/2000/svg" width="4.924ex" height="2.06ex" role="img" focusable="false" viewBox="0 -899.7 2176.4 910.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374 564 388 566 390T582 393Q603 393 603 385 603 376 594 346T558 261 497 161L486 147 487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62 597 56 591 43 579 19 556 5T512-10H505Q438-10 414 62L411 69 400 61Q390 53 370 41T325 18 267-2 203-11Q124-11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290 382 405 304 405 235 405 183 332 156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(673,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(750,0)"><path data-c="2C" d="M78 35T78 60 94 103 137 121Q165 121 187 96T210 8Q210-27 201-60T180-117 154-158 130-185 117-194Q113-194 104-185T95-172Q95-168 106-156T131-126 157-76 173-3V9L172 8Q170 7 167 6T161 3 152 1 140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(1028,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(394,363) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560 218 560 240 545T262 501Q262 496 260 486 259 479 173 263T84 45 79 43Z"></path></g></g><g data-mml-node="mo" transform="translate(1666.5,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g></g></g></svg></mjx-container></span>将被用来计算每个时间步<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.025ex" xmlns="http://www.w3.org/2000/svg" width="0.817ex" height="1.441ex" role="img" focusable="false" viewBox="0 -626 361 637"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g></g></g></svg></mjx-container></span>的上下文变量<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.025ex" xmlns="http://www.w3.org/2000/svg" width="9.426ex" height="2.046ex" role="img" focusable="false" viewBox="0 -893.3 4166.4 904.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325 330 359 352 380 366 386H367Q367 388 361 392T340 400 306 404Q276 404 249 390 228 381 206 359 162 315 142 235T121 119Q121 73 147 50 169 26 205 26H209Q321 26 394 111 403 121 406 121 410 121 419 112T429 98 420 83 391 55 346 25 282 0 202-11Q127-11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(433,0)"><path data-c="1D45C" d="M201-11Q126-11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441 333 441 341 440 354 437 367 433T402 417 438 387 464 338 476 268Q476 161 390 75T201-11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375 346 405 306 405 243 405 195 347 158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(918,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341 56 388 89 425 135 442Q171 442 195 424T225 390 231 369Q231 367 232 367L243 378Q304 442 382 442 436 442 469 415T503 336 465 179 427 52Q427 26 444 26 450 26 453 27 482 32 505 65T540 145Q542 153 560 153 580 153 580 145 580 144 576 130 568 101 554 73T508 17 439-10Q392-10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291 189 157Q156 26 151 16 138-11 108-11 95-11 87-5T76 7 74 17Q74 30 112 180T152 343Q153 348 153 366 153 405 129 405 91 405 66 305 60 285 60 284 58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1518,0)"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1879,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350 174 402 244 433 307 442H310Q355 442 388 420T421 355Q421 265 310 237 261 224 176 223 139 223 138 221 138 219 132 186T125 128Q125 81 146 54T209 26 302 45 394 111Q403 121 406 121 410 121 419 112T429 98 420 82 390 55 344 24 281-1 205-11Q126-11 83 42T39 168ZM373 353Q367 405 305 405 272 405 244 391T199 357 170 316 154 280 149 261Q149 260 169 260 282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(2345,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442 467 442 494 420T522 361Q522 332 508 314T481 292 458 288Q439 288 427 299T415 328Q415 374 465 391 454 404 425 404 412 404 406 402 368 386 350 336 290 115 290 78 290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145 504 144 502 134 486 77 440 33T333-11Q263-11 227 52 186-10 133-10H127Q78-10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101 142 81 130 66T107 46 94 41L91 40Q91 39 97 36T113 29 132 26Q168 26 194 71 203 87 217 139T245 247 261 313Q266 340 266 352 266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="msup" transform="translate(2917,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(750,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g></g></g></svg></mjx-container></span>。</p><table><thead><tr class="header"><th style="text-align:center">Attention 机制</th><th style="text-align:center">Attention step</th></tr></thead><tbody><tr class="odd"><td style="text-align:center"><img src="attn_model.png"></td><td style="text-align:center"><img src="attn_mechanism.png"></td></tr></tbody></table><p>值得注意的是左图中有两个 LSTM 网络，下面在 attention 机制之前的是一个双向的 LSTM 网络，被称为 pre-attention Bi-LSTM；上面在 attention 机制之后的是一个单向的 LSTM 网络，被称为 post-attention LSTM。pre-attention Bi-LSTM 一共有<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.357ex" xmlns="http://www.w3.org/2000/svg" width="2.424ex" height="1.889ex" role="img" focusable="false" viewBox="0 -677 1071.5 834.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445 21 450 37 501T71 602L88 651Q93 669 101 677H569 659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437 640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631 469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46 418 46 427 45T436 36Q436 31 433 22 429 4 424 1L422 0Q419 0 415 0 410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83 94Q174 46 189 55 190 56 191 56 196 59 201 76T241 233Q258 301 269 344 339 619 339 625 339 630 310 630H279Q212 630 191 624 146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mi" transform="translate(617,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442 467 442 494 420T522 361Q522 332 508 314T481 292 458 288Q439 288 427 299T415 328Q415 374 465 391 454 404 425 404 412 404 406 402 368 386 350 336 290 115 290 78 290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145 504 144 502 134 486 77 440 33T333-11Q263-11 227 52 186-10 133-10H127Q78-10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101 142 81 130 66T107 46 94 41L91 40Q91 39 97 36T113 29 132 26Q168 26 194 71 203 87 217 139T245 247 261 313Q266 340 266 352 266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g></svg></mjx-container></span>个时间步，post-attention LSTM 一共有<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.667ex" xmlns="http://www.w3.org/2000/svg" width="2.293ex" height="2.199ex" role="img" focusable="false" viewBox="0 -677 1013.5 972"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445 21 450 37 501T71 602L88 651Q93 669 101 677H569 659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437 640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631 469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46 418 46 427 45T436 36Q436 31 433 22 429 4 424 1L422 0Q419 0 415 0 410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83 94Q174 46 189 55 190 56 191 56 196 59 201 76T241 233Q258 301 269 344 339 619 339 625 339 630 310 630H279Q212 630 191 624 146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mi" transform="translate(617,-150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406 158 442Q199 442 224 419T250 355Q248 336 247 334 247 331 231 288T198 191 182 105Q182 62 196 45T238 27Q261 27 281 38T312 61 339 94Q339 95 344 114T358 173 377 247Q415 397 419 404 432 431 462 431 475 431 483 424T494 412 496 403Q496 390 447 193T391-23Q363-106 294-155T156-205Q111-205 77-183T43-117Q43-95 50-80T69-58 89-48 106-45Q150-45 150-87 150-107 138-122T115-142 102-147L99-148Q101-153 118-160T152-167H160Q177-167 186-165 219-156 247-127T290-65 313-9 321 21L315 17Q309 13 296 6T270-6Q250-11 231-11 185-11 150 11T104 82Q103 89 103 113 103 170 138 262T173 379Q173 380 173 381 173 390 173 393T169 400 158 404H154Q131 404 112 385T82 344 65 302 57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container></span>个时间步。</p><p>Post-attention LSTM 会将隐藏状态<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.023ex" xmlns="http://www.w3.org/2000/svg" width="3.071ex" height="2.044ex" role="img" focusable="false" viewBox="0 -893.3 1357.4 903.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415 300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372 367 378Q368 378 368 379 368 382 361 388T336 399 297 405Q249 405 227 379T204 326Q204 301 223 291T278 274 330 259Q396 230 396 163 396 135 385 107T352 51 289 7 195-10Q118-10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34 201 27Q237 27 263 38T301 66 318 97 323 122Q323 150 302 164T254 181 195 196 148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(502,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(750,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g></g></g></svg></mjx-container></span>(与生成型模型不同，前一个字符和下一个字符之间没有很强的依赖，因此不是输出而是隐藏状态)和细胞的状态<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.025ex" xmlns="http://www.w3.org/2000/svg" width="2.99ex" height="2.046ex" role="img" focusable="false" viewBox="0 -893.3 1321.4 904.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325 330 359 352 380 366 386H367Q367 388 361 392T340 400 306 404Q276 404 249 390 228 381 206 359 162 315 142 235T121 119Q121 73 147 50 169 26 205 26H209Q321 26 394 111 403 121 406 121 410 121 419 112T429 98 420 83 391 55 346 25 282 0 202-11Q127-11 81 37T34 159Z"></path></g><g data-mml-node="TeXAtom" transform="translate(466,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(750,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g></g></g></svg></mjx-container></span>传输给下一个时间步。模型的实现如下所示：</p><ol type="1"><li><p><strong><code>one_step_attention()</code></strong>：在时间步<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.025ex" xmlns="http://www.w3.org/2000/svg" width="0.817ex" height="1.441ex" role="img" focusable="false" viewBox="0 -626 361 637"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g></g></g></svg></mjx-container></span>，给定 pre-attention Bi-LSTM 的隐藏状态<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.566ex" xmlns="http://www.w3.org/2000/svg" width="18.496ex" height="2.587ex" role="img" focusable="false" viewBox="0 -893.3 8175.1 1143.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="5B" d="M118-250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="msup" transform="translate(278,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392 386 422 416 422 429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35 443 55 463 131 469 151 473 152 475 153 483 153H487Q506 153 506 144 506 138 501 117T481 63 449 13Q436 0 417-8 409-10 393-10 359-10 336 5T306 36L300 51Q299 52 296 50 294 48 292 46 233-10 172-10 117-10 75 30T33 157ZM351 328Q351 334 346 350T323 385 277 405Q242 405 210 374T160 293Q131 214 119 129 119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="mn" transform="translate(389,0)"><path data-c="31" d="M213 578 200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641 273 663Q275 666 285 666 294 666 302 660V361L303 61Q310 54 315 52T339 48 401 46H427V0H416Q395 3 257 3 121 3 100 0H88V46H114Q136 46 152 46T177 47 193 50 201 52 207 57 213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(889,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1793.7,0)"><path data-c="2C" d="M78 35T78 60 94 103 137 121Q165 121 187 96T210 8Q210-27 201-60T180-117 154-158 130-185 117-194Q113-194 104-185T95-172Q95-168 106-156T131-126 157-76 173-3V9L172 8Q170 7 167 6T161 3 152 1 140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(2238.3,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392 386 422 416 422 429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35 443 55 463 131 469 151 473 152 475 153 483 153H487Q506 153 506 144 506 138 501 117T481 63 449 13Q436 0 417-8 409-10 393-10 359-10 336 5T306 36L300 51Q299 52 296 50 294 48 292 46 233-10 172-10 117-10 75 30T33 157ZM351 328Q351 334 346 350T323 385 277 405Q242 405 210 374T160 293Q131 214 119 129 119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="mn" transform="translate(389,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315 301 241Q265 210 201 149L142 93 218 92Q375 92 385 97 392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19 31Q50 38 56 46T86 81Q115 113 136 137 145 147 170 174T204 211 233 244 261 278 284 308 305 340 320 369 333 401 340 431 343 464Q343 527 309 573T212 619Q179 619 154 602T119 569 109 550Q109 549 114 549 132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(889,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3754,0)"><path data-c="2C" d="M78 35T78 60 94 103 137 121Q165 121 187 96T210 8Q210-27 201-60T180-117 154-158 130-185 117-194Q113-194 104-185T95-172Q95-168 106-156T131-126 157-76 173-3V9L172 8Q170 7 167 6T161 3 152 1 140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(4198.7,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0 96 17 78 60Z"></path></g><g data-mml-node="mo" transform="translate(4643.4,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0 96 17 78 60Z"></path></g><g data-mml-node="mo" transform="translate(5088,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0 96 17 78 60Z"></path></g><g data-mml-node="mo" transform="translate(5532.7,0)"><path data-c="2C" d="M78 35T78 60 94 103 137 121Q165 121 187 96T210 8Q210-27 201-60T180-117 154-158 130-185 117-194Q113-194 104-185T95-172Q95-168 106-156T131-126 157-76 173-3V9L172 8Q170 7 167 6T161 3 152 1 140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(5977.4,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392 386 422 416 422 429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35 443 55 463 131 469 151 473 152 475 153 483 153H487Q506 153 506 144 506 138 501 117T481 63 449 13Q436 0 417-8 409-10 393-10 359-10 336 5T306 36L300 51Q299 52 296 50 294 48 292 46 233-10 172-10 117-10 75 30T33 157ZM351 328Q351 334 346 350T323 385 277 405Q242 405 210 374T160 293Q131 214 119 129 119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445 21 450 37 501T71 602L88 651Q93 669 101 677H569 659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437 640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631 469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46 418 46 427 45T436 36Q436 31 433 22 429 4 424 1L422 0Q419 0 415 0 410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83 94Q174 46 189 55 190 56 191 56 196 59 201 76T241 233Q258 301 269 344 339 619 339 625 339 630 310 630H279Q212 630 191 624 146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mi" transform="translate(617,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442 467 442 494 420T522 361Q522 332 508 314T481 292 458 288Q439 288 427 299T415 328Q415 374 465 391 454 404 425 404 412 404 406 402 368 386 350 336 290 115 290 78 290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145 504 144 502 134 486 77 440 33T333-11Q263-11 227 52 186-10 133-10H127Q78-10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101 142 81 130 66T107 46 94 41L91 40Q91 39 97 36T113 29 132 26Q168 26 194 71 203 87 217 139T245 247 261 313Q266 340 266 352 266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(1460.5,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g><g data-mml-node="mo" transform="translate(7897.1,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container></span>和 post-attention LSTM 上一个时间步的隐藏状态<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.023ex" xmlns="http://www.w3.org/2000/svg" width="5.116ex" height="2.044ex" role="img" focusable="false" viewBox="0 -893.3 2261.1 903.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415 300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372 367 378Q368 378 368 379 368 382 361 388T336 399 297 405Q249 405 227 379T204 326Q204 301 223 291T278 274 330 259Q396 230 396 163 396 135 385 107T352 51 289 7 195-10Q118-10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34 201 27Q237 27 263 38T301 66 318 97 323 122Q323 150 302 164T254 181 195 196 148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(502,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(750,0)"><path data-c="2212" d="M84 237T84 250 98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1528,0)"><path data-c="31" d="M213 578 200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641 273 663Q275 666 285 666 294 666 302 660V361L303 61Q310 54 315 52T339 48 401 46H427V0H416Q395 3 257 3 121 3 100 0H88V46H114Q136 46 152 46T177 47 193 50 201 52 207 57 213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(2028,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g></g></g></svg></mjx-container></span>。<code>one_step_attention()</code> 计算将会计算 attention 的权值和上下文变量：<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align:-2.849ex" xmlns="http://www.w3.org/2000/svg" width="24.662ex" height="6.811ex" role="img" focusable="false" viewBox="0 -1751.3 10900.6 3010.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325 330 359 352 380 366 386H367Q367 388 361 392T340 400 306 404Q276 404 249 390 228 381 206 359 162 315 142 235T121 119Q121 73 147 50 169 26 205 26H209Q321 26 394 111 403 121 406 121 410 121 419 112T429 98 420 83 391 55 346 25 282 0 202-11Q127-11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(433,0)"><path data-c="1D45C" d="M201-11Q126-11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441 333 441 341 440 354 437 367 433T402 417 438 387 464 338 476 268Q476 161 390 75T201-11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375 346 405 306 405 243 405 195 347 158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(918,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341 56 388 89 425 135 442Q171 442 195 424T225 390 231 369Q231 367 232 367L243 378Q304 442 382 442 436 442 469 415T503 336 465 179 427 52Q427 26 444 26 450 26 453 27 482 32 505 65T540 145Q542 153 560 153 580 153 580 145 580 144 576 130 568 101 554 73T508 17 439-10Q392-10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291 189 157Q156 26 151 16 138-11 108-11 95-11 87-5T76 7 74 17Q74 30 112 180T152 343Q153 348 153 366 153 405 129 405 91 405 66 305 60 285 60 284 58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1518,0)"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1879,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350 174 402 244 433 307 442H310Q355 442 388 420T421 355Q421 265 310 237 261 224 176 223 139 223 138 221 138 219 132 186T125 128Q125 81 146 54T209 26 302 45 394 111Q403 121 406 121 410 121 419 112T429 98 420 82 390 55 344 24 281-1 205-11Q126-11 83 42T39 168ZM373 353Q367 405 305 405 272 405 244 391T199 357 170 316 154 280 149 261Q149 260 169 260 282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(2345,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442 467 442 494 420T522 361Q522 332 508 314T481 292 458 288Q439 288 427 299T415 328Q415 374 465 391 454 404 425 404 412 404 406 402 368 386 350 336 290 115 290 78 290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145 504 144 502 134 486 77 440 33T333-11Q263-11 227 52 186-10 133-10H127Q78-10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101 142 81 130 66T107 46 94 41L91 40Q91 39 97 36T113 29 132 26Q168 26 194 71 203 87 217 139T245 247 261 313Q266 340 266 352 266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="msup" transform="translate(2917,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(750,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4444.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347 722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153 722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="munderover" transform="translate(5500,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761 1235 809 1174 838T1033 881 882 898 699 902H574 543 251L259 891Q722 258 724 252 725 250 724 246 721 243 460-56L196-356Q196-357 407-357 459-357 548-357T676-358Q812-358 896-353T1063-332 1204-283 1307-196Q1328-170 1348-124H1388Q1388-125 1381-145T1356-210 1325-294L1267-449 666-450Q64-450 61-448 55-446 55-439 55-437 57-433L590 177Q590 178 557 222T452 366 322 544L56 909 55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(44.4,-1101.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(394,289) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560 218 560 240 545T262 501Q262 496 260 486 259 479 173 263T84 45 79 43Z"></path></g></g><g data-mml-node="mo" transform="translate(638.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347 722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153 722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1416.5,0)"><path data-c="30" d="M96 585Q152 666 249 666 297 666 345 640T423 548Q460 465 460 320 460 165 417 83 397 41 362 16T301-15 250-22Q224-22 198-16T137 16 82 83Q39 165 39 320 39 494 96 585ZM321 597Q291 629 250 629 208 629 178 597 153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16 290 16 318 46 347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(343.2,1172.6) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445 21 450 37 501T71 602L88 651Q93 669 101 677H569 659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437 640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631 469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46 418 46 427 45T436 36Q436 31 433 22 429 4 424 1L422 0Q419 0 415 0 410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83 94Q174 46 189 55 190 56 191 56 196 59 201 76T241 233Q258 301 269 344 339 619 339 625 339 630 310 630H279Q212 630 191 624 146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mi" transform="translate(617,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442 467 442 494 420T522 361Q522 332 508 314T481 292 458 288Q439 288 427 299T415 328Q415 374 465 391 454 404 425 404 412 404 406 402 368 386 350 336 290 115 290 78 290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145 504 144 502 134 486 77 440 33T333-11Q263-11 227 52 186-10 133-10H127Q78-10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101 142 81 130 66T107 46 94 41L91 40Q91 39 97 36T113 29 132 26Q168 26 194 71 203 87 217 139T245 247 261 313Q266 340 266 352 266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g><g data-mml-node="msup" transform="translate(7110.6,0)"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374 564 388 566 390T582 393Q603 393 603 385 603 376 594 346T558 261 497 161L486 147 487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62 597 56 591 43 579 19 556 5T512-10H505Q438-10 414 62L411 69 400 61Q390 53 370 41T325 18 267-2 203-11Q124-11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290 382 405 304 405 235 405 183 332 156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(673,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(750,0)"><path data-c="2C" d="M78 35T78 60 94 103 137 121Q165 121 187 96T210 8Q210-27 201-60T180-117 154-158 130-185 117-194Q113-194 104-185T95-172Q95-168 106-156T131-126 157-76 173-3V9L172 8Q170 7 167 6T161 3 152 1 140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(1028,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(394,363) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560 218 560 240 545T262 501Q262 496 260 486 259 479 173 263T84 45 79 43Z"></path></g></g><g data-mml-node="mo" transform="translate(1666.5,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g><g data-mml-node="msup" transform="translate(9287,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392 386 422 416 422 429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35 443 55 463 131 469 151 473 152 475 153 483 153H487Q506 153 506 144 506 138 501 117T481 63 449 13Q436 0 417-8 409-10 393-10 359-10 336 5T306 36L300 51Q299 52 296 50 294 48 292 46 233-10 172-10 117-10 75 30T33 157ZM351 328Q351 334 346 350T323 385 277 405Q242 405 210 374T160 293Q131 214 119 129 119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="msup" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(394,363) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560 218 560 240 545T262 501Q262 496 260 486 259 479 173 263T84 45 79 43Z"></path></g></g><g data-mml-node="mo" transform="translate(1027.5,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g></g></g></svg></mjx-container></span>Keras 实现 <strong><code>one_step_attention()</code></strong> 代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">repeator = RepeatVector(Tx)</span><br><span class="line">concatenator = Concatenate(axis=-<span class="number">1</span>)</span><br><span class="line">densor1 = Dense(<span class="number">10</span>, activation = <span class="string">"tanh"</span>)</span><br><span class="line">densor2 = Dense(<span class="number">1</span>, activation = <span class="string">"relu"</span>)</span><br><span class="line">activator = Activation(softmax, name=<span class="string">'attention_weights'</span>) <span class="comment"># We are using a custom softmax(axis = 1) loaded in this notebook</span></span><br><span class="line">dotor = Dot(axes = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">one_step_attention</span>(<span class="params">a, s_prev</span>):</span><br><span class="line">    <span class="comment"># Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states "a" (≈ 1 line)</span></span><br><span class="line">    s_prev = repeator(s_prev)</span><br><span class="line">    <span class="comment"># Use concatenator to concatenate a and s_prev on the last axis (≈ 1 line)</span></span><br><span class="line">    concat = concatenator([a, s_prev])</span><br><span class="line">    <span class="comment"># Use densor1 to propagate concat through a small fully-connected neural network to compute the "intermediate energies" variable e. (≈1 lines)</span></span><br><span class="line">    e = densor1(concat)</span><br><span class="line">    <span class="comment"># Use densor2 to propagate e through a small fully-connected neural network to compute the "energies" variable energies. (≈1 lines)</span></span><br><span class="line">    energies = densor2(e)</span><br><span class="line">    <span class="comment"># Use "activator" on "energies" to compute the attention weights "alphas" (≈ 1 line)</span></span><br><span class="line">    alphas = activator(energies)</span><br><span class="line">    <span class="comment"># Use dotor together with "alphas" and "a" to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)</span></span><br><span class="line">    context = dotor([alphas, a])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> context</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong><code>model()</code></strong>：实现整个模型。首先运行 Bi-LSTM 获取<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.566ex" xmlns="http://www.w3.org/2000/svg" width="18.496ex" height="2.587ex" role="img" focusable="false" viewBox="0 -893.3 8175.1 1143.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="5B" d="M118-250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="msup" transform="translate(278,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392 386 422 416 422 429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35 443 55 463 131 469 151 473 152 475 153 483 153H487Q506 153 506 144 506 138 501 117T481 63 449 13Q436 0 417-8 409-10 393-10 359-10 336 5T306 36L300 51Q299 52 296 50 294 48 292 46 233-10 172-10 117-10 75 30T33 157ZM351 328Q351 334 346 350T323 385 277 405Q242 405 210 374T160 293Q131 214 119 129 119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="mn" transform="translate(389,0)"><path data-c="31" d="M213 578 200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641 273 663Q275 666 285 666 294 666 302 660V361L303 61Q310 54 315 52T339 48 401 46H427V0H416Q395 3 257 3 121 3 100 0H88V46H114Q136 46 152 46T177 47 193 50 201 52 207 57 213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(889,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g><g data-mml-node="mo" transform="translate(1793.7,0)"><path data-c="2C" d="M78 35T78 60 94 103 137 121Q165 121 187 96T210 8Q210-27 201-60T180-117 154-158 130-185 117-194Q113-194 104-185T95-172Q95-168 106-156T131-126 157-76 173-3V9L172 8Q170 7 167 6T161 3 152 1 140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(2238.3,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392 386 422 416 422 429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35 443 55 463 131 469 151 473 152 475 153 483 153H487Q506 153 506 144 506 138 501 117T481 63 449 13Q436 0 417-8 409-10 393-10 359-10 336 5T306 36L300 51Q299 52 296 50 294 48 292 46 233-10 172-10 117-10 75 30T33 157ZM351 328Q351 334 346 350T323 385 277 405Q242 405 210 374T160 293Q131 214 119 129 119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="mn" transform="translate(389,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315 301 241Q265 210 201 149L142 93 218 92Q375 92 385 97 392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19 31Q50 38 56 46T86 81Q115 113 136 137 145 147 170 174T204 211 233 244 261 278 284 308 305 340 320 369 333 401 340 431 343 464Q343 527 309 573T212 619Q179 619 154 602T119 569 109 550Q109 549 114 549 132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(889,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g><g data-mml-node="mo" transform="translate(3754,0)"><path data-c="2C" d="M78 35T78 60 94 103 137 121Q165 121 187 96T210 8Q210-27 201-60T180-117 154-158 130-185 117-194Q113-194 104-185T95-172Q95-168 106-156T131-126 157-76 173-3V9L172 8Q170 7 167 6T161 3 152 1 140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(4198.7,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0 96 17 78 60Z"></path></g><g data-mml-node="mo" transform="translate(4643.4,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0 96 17 78 60Z"></path></g><g data-mml-node="mo" transform="translate(5088,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0 96 17 78 60Z"></path></g><g data-mml-node="mo" transform="translate(5532.7,0)"><path data-c="2C" d="M78 35T78 60 94 103 137 121Q165 121 187 96T210 8Q210-27 201-60T180-117 154-158 130-185 117-194Q113-194 104-185T95-172Q95-168 106-156T131-126 157-76 173-3V9L172 8Q170 7 167 6T161 3 152 1 140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(5977.4,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392 386 422 416 422 429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35 443 55 463 131 469 151 473 152 475 153 483 153H487Q506 153 506 144 506 138 501 117T481 63 449 13Q436 0 417-8 409-10 393-10 359-10 336 5T306 36L300 51Q299 52 296 50 294 48 292 46 233-10 172-10 117-10 75 30T33 157ZM351 328Q351 334 346 350T323 385 277 405Q242 405 210 374T160 293Q131 214 119 129 119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445 21 450 37 501T71 602L88 651Q93 669 101 677H569 659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437 640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631 469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46 418 46 427 45T436 36Q436 31 433 22 429 4 424 1L422 0Q419 0 415 0 410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83 94Q174 46 189 55 190 56 191 56 196 59 201 76T241 233Q258 301 269 344 339 619 339 625 339 630 310 630H279Q212 630 191 624 146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mi" transform="translate(617,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442 467 442 494 420T522 361Q522 332 508 314T481 292 458 288Q439 288 427 299T415 328Q415 374 465 391 454 404 425 404 412 404 406 402 368 386 350 336 290 115 290 78 290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145 504 144 502 134 486 77 440 33T333-11Q263-11 227 52 186-10 133-10H127Q78-10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101 142 81 130 66T107 46 94 41L91 40Q91 39 97 36T113 29 132 26Q168 26 194 71 203 87 217 139T245 247 261 313Q266 340 266 352 266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(1460.5,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g><g data-mml-node="mo" transform="translate(7897.1,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container></span>。然后运行 <code>one_step_attention()</code><span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.667ex" xmlns="http://www.w3.org/2000/svg" width="2.293ex" height="2.199ex" role="img" focusable="false" viewBox="0 -677 1013.5 972"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445 21 450 37 501T71 602L88 651Q93 669 101 677H569 659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437 640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631 469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46 418 46 427 45T436 36Q436 31 433 22 429 4 424 1L422 0Q419 0 415 0 410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83 94Q174 46 189 55 190 56 191 56 196 59 201 76T241 233Q258 301 269 344 339 619 339 625 339 630 310 630H279Q212 630 191 624 146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mi" transform="translate(617,-150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406 158 442Q199 442 224 419T250 355Q248 336 247 334 247 331 231 288T198 191 182 105Q182 62 196 45T238 27Q261 27 281 38T312 61 339 94Q339 95 344 114T358 173 377 247Q415 397 419 404 432 431 462 431 475 431 483 424T494 412 496 403Q496 390 447 193T391-23Q363-106 294-155T156-205Q111-205 77-183T43-117Q43-95 50-80T69-58 89-48 106-45Q150-45 150-87 150-107 138-122T115-142 102-147L99-148Q101-153 118-160T152-167H160Q177-167 186-165 219-156 247-127T290-65 313-9 321 21L315 17Q309 13 296 6T270-6Q250-11 231-11 185-11 150 11T104 82Q103 89 103 113 103 170 138 262T173 379Q173 380 173 381 173 390 173 393T169 400 158 404H154Q131 404 112 385T82 344 65 302 57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container></span>个时间步（每个时间步共享权值参数），对于每一个时间步，首先计算上下文变量，然后运行 post-attention LSTM，其输出经过带有 softmax 激活函数的全连接层网络后生成预测<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.464ex" xmlns="http://www.w3.org/2000/svg" width="3.119ex" height="2.485ex" role="img" focusable="false" viewBox="0 -893.3 1378.4 1098.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406 158 442Q199 442 224 419T250 355Q248 336 247 334 247 331 231 288T198 191 182 105Q182 62 196 45T238 27Q261 27 281 38T312 61 339 94Q339 95 344 114T358 173 377 247Q415 397 419 404 432 431 462 431 475 431 483 424T494 412 496 403Q496 390 447 193T391-23Q363-106 294-155T156-205Q111-205 77-183T43-117Q43-95 50-80T69-58 89-48 106-45Q150-45 150-87 150-107 138-122T115-142 102-147L99-148Q101-153 118-160T152-167H160Q177-167 186-165 219-156 247-127T290-65 313-9 321 21L315 17Q309 13 296 6T270-6Q250-11 231-11 185-11 150 11T104 82Q103 89 103 113 103 170 138 262T173 379Q173 380 173 381 173 390 173 393T169 400 158 404H154Q131 404 112 385T82 344 65 302 57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560 249 694 257 686Q387 562 387 560L361 531Q359 532 303 581L250 627 195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="TeXAtom" transform="translate(523,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(750,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g></g></g></svg></mjx-container></span>。 Keras 实现 <strong><code>model()</code></strong> 代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">n_a = <span class="number">32</span></span><br><span class="line">n_s = <span class="number">64</span></span><br><span class="line">post_activation_LSTM_cell = LSTM(n_s, return_state = <span class="literal">True</span>)</span><br><span class="line">output_layer = Dense(<span class="built_in">len</span>(machine_vocab), activation=softmax)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model</span>(<span class="params">Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size</span>):</span><br><span class="line">    <span class="comment"># Define the inputs of your model with a shape (Tx,)</span></span><br><span class="line">    <span class="comment"># Define s0 and c0, initial hidden state for the decoder LSTM of shape (n_s,)</span></span><br><span class="line">    X = Input(shape=(Tx, human_vocab_size))</span><br><span class="line">    s0 = Input(shape=(n_s,), name=<span class="string">'s0'</span>)</span><br><span class="line">    c0 = Input(shape=(n_s,), name=<span class="string">'c0'</span>)</span><br><span class="line">    s = s0</span><br><span class="line">    c = c0</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize empty list of outputs</span></span><br><span class="line">    outputs = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Define your pre-attention Bi-LSTM. Remember to use return_sequences=True. (≈ 1 line)</span></span><br><span class="line">    a = Bidirectional(LSTM(n_a, return_sequences=<span class="literal">True</span>), input_shape=(m, Tx, n_a * <span class="number">2</span>))(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: Iterate for Ty steps</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(Ty):</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t (≈ 1 line)</span></span><br><span class="line">        context = one_step_attention(a, s)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2.B: Apply the post-attention LSTM cell to the "context" vector.</span></span><br><span class="line">        <span class="comment"># Don't forget to pass: initial_state = [hidden state, cell state] (≈ 1 line)</span></span><br><span class="line">        s, _, c = post_activation_LSTM_cell(context, initial_state=[s, c])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM (≈ 1 line)</span></span><br><span class="line">        out = output_layer(s)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 2.D: Append "out" to the "outputs" list (≈ 1 line)</span></span><br><span class="line">        outputs.append(out)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 3: Create model instance taking three inputs and returning the list of outputs. (≈ 1 line)</span></span><br><span class="line">    model = Model(inputs=[X, s0, c0], outputs=outputs)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></li></ol><p>然后可以使用<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.566ex" xmlns="http://www.w3.org/2000/svg" width="11.414ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 5045 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415 300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372 367 378Q368 378 368 379 368 382 361 388T336 399 297 405Q249 405 227 379T204 326Q204 301 223 291T278 274 330 259Q396 230 396 163 396 135 385 107T352 51 289 7 195-10Q118-10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34 201 27Q237 27 263 38T301 66 318 97 323 122Q323 150 302 164T254 181 195 196 148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(469,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370 99 420 158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27 291 44 328 78L339 95Q341 99 377 247 407 367 413 387T427 416Q444 431 463 431 480 431 488 421T496 402L420 84Q419 79 419 68 419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153 551 153 551 144 550 139 549 130T540 98 523 55 498 17 462-8Q454-10 438-10 372-10 347 46 345 45 336 36T318 21 296 6 267-6 233-11Q189-11 155 7 103 38 103 113 103 170 138 262T173 379Q173 380 173 381 173 390 173 393T169 400 158 404H154Q131 404 112 385T82 344 65 302 57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1041,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341 56 388 88 425 132 442 175 435 205 417 221 395 229 376L231 369Q231 367 232 367L243 378Q303 442 384 442 401 442 415 440T441 433 460 423 475 411 485 398 493 385 497 373 500 364 502 357L510 367Q573 442 659 442 713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145 857 144 853 130 845 101 831 73T785 17 716-10Q669-10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291 466 157Q433 26 428 16 415-11 385-11 372-11 364-4T353 8 350 18Q350 29 384 161L420 307Q423 322 423 345 423 404 379 404H374Q288 404 229 303L222 291 189 157Q156 26 151 16 138-11 108-11 95-11 87-5T76 7 74 17Q74 30 112 181 151 335 151 342 154 357 154 369 154 405 129 405 107 405 92 377T69 316 57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1919,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341 56 388 88 425 132 442 175 435 205 417 221 395 229 376L231 369Q231 367 232 367L243 378Q303 442 384 442 401 442 415 440T441 433 460 423 475 411 485 398 493 385 497 373 500 364 502 357L510 367Q573 442 659 442 713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145 857 144 853 130 845 101 831 73T785 17 716-10Q669-10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291 466 157Q433 26 428 16 415-11 385-11 372-11 364-4T353 8 350 18Q350 29 384 161L420 307Q423 322 423 345 423 404 379 404H374Q288 404 229 303L222 291 189 157Q156 26 151 16 138-11 108-11 95-11 87-5T76 7 74 17Q74 30 112 181 151 335 151 342 154 357 154 369 154 405 129 405 107 405 92 377T69 316 57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2797,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392 386 422 416 422 429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35 443 55 463 131 469 151 473 152 475 153 483 153H487Q506 153 506 144 506 138 501 117T481 63 449 13Q436 0 417-8 409-10 393-10 359-10 336 5T306 36L300 51Q299 52 296 50 294 48 292 46 233-10 172-10 117-10 75 30T33 157ZM351 328Q351 334 346 350T323 385 277 405Q242 405 210 374T160 293Q131 214 119 129 119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(3326,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317 38 348 53 381 73 411 99 433 132 442Q161 442 183 430T214 408 225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400 430 381 430 363 430 333 417 315T391 292 366 288Q346 288 334 299T322 328Q322 376 378 392 356 405 342 405 286 405 239 331 229 315 224 298T190 165Q156 25 151 16 138-11 108-11 95-11 87-5T76 7 74 17Q74 30 114 189T154 366Q154 405 128 405 107 405 92 377T68 316 57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3777,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406 158 442Q199 442 224 419T250 355Q248 336 247 334 247 331 231 288T198 191 182 105Q182 62 196 45T238 27Q261 27 281 38T312 61 339 94Q339 95 344 114T358 173 377 247Q415 397 419 404 432 431 462 431 475 431 483 424T494 412 496 403Q496 390 447 193T391-23Q363-106 294-155T156-205Q111-205 77-183T43-117Q43-95 50-80T69-58 89-48 106-45Q150-45 150-87 150-107 138-122T115-142 102-147L99-148Q101-153 118-160T152-167H160Q177-167 186-165 219-156 247-127T290-65 313-9 321 21L315 17Q309 13 296 6T270-6Q250-11 231-11 185-11 150 11T104 82Q103 89 103 113 103 170 138 262T173 379Q173 380 173 381 173 390 173 393T169 400 158 404H154Q131 404 112 385T82 344 65 302 57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4267,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488 164 576 202 643 244 695 277 729 302 750H315 319Q333 750 333 741 333 738 316 720T275 667 226 581 184 443 167 250 184 58 225-81 274-167 316-220 333-241Q333-250 318-250H315 302L274-226Q180-141 137-14T94 250Z"></path></g><g data-mml-node="mo" transform="translate(4656,0)"><path data-c="29" d="M60 749 64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12 224-76 186-143 145-194 113-227 90-246Q87-249 86-250H74Q66-250 63-250T58-247 55-238Q56-237 66-225 221-64 221 250T66 725Q56 737 55 738 55 746 60 749Z"></path></g></g></g></svg></mjx-container></span>查看模型概况：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = model(Tx, Ty, n_a, n_s, <span class="built_in">len</span>(human_vocab), <span class="built_in">len</span>(machine_vocab))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><h2 id="优化">优化</h2><p>创建完模型后则需要需要定义损失函数、优化器和度量标准：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">opt = Adam(lr=<span class="number">0.005</span>, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, decay=<span class="number">0.01</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=opt, metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure><p>最后定义拟合模型的输入和输出，拟合模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s0 = np.zeros((m, n_s))</span><br><span class="line">c0 = np.zeros((m, n_s))</span><br><span class="line">outputs = <span class="built_in">list</span>(Yoh.swapaxes(<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line">model.fit([Xoh, s0, c0], outputs, epochs=<span class="number">1</span>, batch_size=<span class="number">100</span>)</span><br></pre></td></tr></table></figure><h2 id="可视化-attention">可视化 Attention</h2><p>可以通过输出 attention 层的输出<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.025ex" xmlns="http://www.w3.org/2000/svg" width="4.924ex" height="2.06ex" role="img" focusable="false" viewBox="0 -899.7 2176.4 910.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374 564 388 566 390T582 393Q603 393 603 385 603 376 594 346T558 261 497 161L486 147 487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62 597 56 591 43 579 19 556 5T512-10H505Q438-10 414 62L411 69 400 61Q390 53 370 41T325 18 267-2 203-11Q124-11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290 382 405 304 405 235 405 183 332 156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(673,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="27E8" d="M333-232Q332-239 327-244T313-250Q303-250 296-240 293-233 202 6T110 250 201 494 296 740Q299 745 306 749L309 750Q312 750 313 750 331 750 333 732 333 727 243 489 152 252 152 250T243 11Q333-227 333-232Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(750,0)"><path data-c="2C" d="M78 35T78 60 94 103 137 121Q165 121 187 96T210 8Q210-27 201-60T180-117 154-158 130-185 117-194Q113-194 104-185T95-172Q95-168 106-156T131-126 157-76 173-3V9L172 8Q170 7 167 6T161 3 152 1 140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(1028,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395 19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566 179 586 187 603 197 615 211 624 229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420 330 398 317 385H210L174 240Q135 80 135 68 135 26 162 26 197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145 322 142 319 133 314 117 301 95T267 48 216 6 155-11Q125-11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383 128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(394,363) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560 218 560 240 545T262 501Q262 496 260 486 259 479 173 263T84 45 79 43Z"></path></g></g><g data-mml-node="mo" transform="translate(1666.5,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740 95 733 186 494T278 250 187 6 92-240Q85-250 75-250 67-250 62-245T55-232Q55-227 145 11 236 248 236 250T145 489Q55 727 55 732Z"></path></g></g></g></g></g></svg></mjx-container></span>来可视化 Attention (实现细节可看 <code>mnt_utils.py</code>)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, <span class="string">"Tuesday 09 Oct 1993"</span>, num = <span class="number">7</span>, n_s = <span class="number">64</span>)</span><br></pre></td></tr></table></figure><p><img src="output.png"></p><p>可以看到输出忽略了 "Tuesday"，在输出日期的时候，注意力明显也是放在输入的日期上，虽然图中月份部分翻译的注意力不是很明显。</p><h2 id="总结">总结</h2><p>机器翻译模型可以将输入的序列匹配成别的序列，注意力机制则可以允许网络在输出时聚焦于与输入相关的部分。总之，这个实验更加强化了 Encoder-Decoder 模型，首先将序列编码成一个定长表示，然后再解码成其他序列。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li></ol></div><div class="reward-container"><div>疏影横斜水清浅，暗香浮动月黄昏</div><button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'>打赏</button><div id="qr" style="display:none"><div style="display:inline-block"><img src="/images/wechatpay.png" alt="Randy Peng 微信支付"><p>微信支付</p></div><div style="display:inline-block"><img src="/images/alipay.png" alt="Randy Peng 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong> Randy Peng</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://pengzhendong.github.io/2018/09/10/neural-machine-translation/" title="自然机器翻译">https://pengzhendong.github.io/2018/09/10/neural-machine-translation/</a></li><li class="post-copyright-license"><strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><center><br><div class="addthis_inline_share_toolbox"><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5aa9d6309315fb5e" async="async"></script></div></center><footer class="post-footer"><div class="post-tags"><a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a></div><div class="post-nav"><div class="post-nav-item"><a href="/2018/08/31/word-vector-representation/" rel="prev" title="词向量表示"><i class="fa fa-chevron-left"></i> 词向量表示</a></div><div class="post-nav-item"><a href="/2018/10/22/wav-file/" rel="next" title="WAV 文件">WAV 文件<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><script>window.addEventListener("tabs:register",()=>{let{activeClass:t}=CONFIG.comments;if(CONFIG.comments.storage&&(t=localStorage.getItem("comments_active")||t),t){let e=document.querySelector(`a[href="#comment-${t}"]`);e&&e.click()}}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{if(!t.target.matches(".tabs-comment .tab-content .tab-pane"))return;let e=t.target.classList[1];localStorage.setItem("comments_active",e)})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">2.</span> <span class="nav-text">数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#attention-%E6%9C%BA%E5%88%B6"><span class="nav-number">3.</span> <span class="nav-text">Attention 机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BC%98%E5%8C%96"><span class="nav-number">4.</span> <span class="nav-text">优化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96-attention"><span class="nav-number">5.</span> <span class="nav-text">可视化 Attention</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">6.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number">7.</span> <span class="nav-text">参考文献</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Randy Peng" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">Randy Peng</p><div class="site-description" itemprop="description">路漫漫其修远兮 吾将上下而求索</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">35</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">7</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/pengzhendong" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;pengzhendong" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="https://twitter.com/pengzhendong" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;pengzhendong" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i> Twitter</a></span><span class="links-of-author-item"><a href="mailto:275331498@qq.com" title="E-Mail → mailto:275331498@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="https://www.facebook.com/pengzhendong" title="FaceBook → https:&#x2F;&#x2F;www.facebook.com&#x2F;pengzhendong" rel="noopener" target="_blank"><i class="fab fa-facebook fa-fw"></i> FaceBook</a></span><span class="links-of-author-item"><a href="https://t.me/pengzhendong" title="Telegram → https:&#x2F;&#x2F;t.me&#x2F;pengzhendong" rel="noopener" target="_blank"><i class="fab fa-telegram fa-fw"></i> Telegram</a></span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/pengzhendong" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;pengzhendong" rel="noopener" target="_blank"><i class="fab fa-leanpub fa-fw"></i> 知乎</a></span><span class="links-of-author-item"><a href="https://weibo.com/qq275331498" title="微博 → https:&#x2F;&#x2F;weibo.com&#x2F;qq275331498" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i> 微博</a></span><span class="links-of-author-item"><a href="/about" title="关于 → &#x2F;about"><i class="fa fa-user fa-fw"></i> 关于</a></span></div><hr style="margin-top:20px;margin-bottom:20px"><img src="/images/wechat.png"></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; 2015 – <span itemprop="copyrightYear">2022</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">Randy Peng</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-chart-area"></i></span> <span title="站点总字数">230k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span title="站点阅读时长">3:29</span></div><script>!function(){function e(e){return e=encodeURI(e),document.getElementById(e).querySelector(".leancloud-visitors-count")}let{app_id:t,app_key:o,server_url:n}={enable:!0,app_id:"YHMwvrTgcfDjOXmiGY3jQ2r5-gzGzoHsz",app_key:"JRfKfM8mRPgxMB9GOSAnix9W",server_url:null,security:!0};function r(n){var r=(e,r,l)=>fetch(`${n}/1.1${r}`,{method:e,headers:{"X-LC-Id":t,"X-LC-Key":o,"Content-Type":"application/json"},body:JSON.stringify(l)});if(CONFIG.page.isPost){if(CONFIG.hostname!==location.hostname)return;!function(t){var o=document.querySelector(".leancloud_visitors"),n=decodeURI(o.id);o.dataset.flagTitle,t("get","/classes/Counter?where="+encodeURIComponent(JSON.stringify({url:n}))).then(e=>e.json()).then(({results:o})=>{if(o.length>0){var r=o[0];e(n).innerText=r.time+1,t("put","/classes/Counter/"+r.objectId,{time:{__op:"Increment",amount:1}}).catch(e=>{console.error("Failed to save visitor count",e)})}else e(n).innerText="Counter not initialized! More info at console err msg.",console.error("ATTENTION! LeanCloud counter has security bug, see how to solve it here: https://github.com/theme-next/hexo-leancloud-counter-security. \n However, you can still use LeanCloud without security, by setting `security` option to `false`.")}).catch(e=>{console.error("LeanCloud Counter Error",e)})}(r)}else document.querySelectorAll(".post-title-link").length>=1&&function(t){var o=[...document.querySelectorAll(".leancloud_visitors")].map(e=>decodeURI(e.id));t("get","/classes/Counter?where="+encodeURIComponent(JSON.stringify({url:{$in:o}}))).then(e=>e.json()).then(({results:t})=>{for(let n of o){let o=t.find(e=>e.url===n);e(n).innerText=o?o.time:0}}).catch(e=>{console.error("LeanCloud Counter Error",e)})}(r)}let l="-MdYXbMMI"!==t.slice(-9)?n:`https://${t.slice(0,8).toLowerCase()}.api.lncldglobal.com`;l?r(l):fetch("https://app-router.leancloud.cn/2/route?appId="+t).then(e=>e.json()).then(({api_server:e})=>{r("https://"+e)})}()</script></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>!function(){var e,t,o=document.getElementsByTagName("link");if(o.length>0)for(i=0;i<o.length;i++)"canonical"==o[i].rel.toLowerCase()&&o[i].href&&(e=o[i].href);t=e?e.split(":")[0]:window.location.protocol.split(":")[0],e||(e=window.location.href),function(){var i=e,o=document.referrer;if(!/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(i)){var n="https"===String(t).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),i&&(n+="&l="+i)):i&&(n+="?l="+i),(new Image).src=n}}(window)}()</script><script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script><script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script><script src="/js/algolia-search.js"></script><script>"undefined"==typeof MathJax?(window.MathJax={loader:{source:{"[tex]/amsCd":"[tex]/amscd","[tex]/AMScd":"[tex]/amscd"}},tex:{inlineMath:{"[+]":[["$","$"]]},tags:"ams"},options:{renderActions:{findScript:[10,e=>{document.querySelectorAll('script[type^="math/tex"]').forEach(t=>{const a=!!t.type.match(/; *mode=display/),n=new e.options.MathItem(t.textContent,e.inputJax[0],a),d=document.createTextNode("");t.parentNode.replaceChild(d,t),n.start={node:d,delim:"",n:0},n.end={node:d,delim:"",n:0},e.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}},function(){var e=document.createElement("script");e.src="//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js",e.defer=!0,document.head.appendChild(e)}()):(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset())</script></body></html>