<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2"><link rel="apple-touch-icon" sizes="180x180" href="/hexo/images/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/hexo/images/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/hexo/images/favicon-16x16.png"><link rel="mask-icon" href="/hexo/images/logo.svg" color="#222"><link rel="stylesheet" href="/hexo/css/main.css"><link rel="stylesheet" href="/hexo/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"pengzhendong.github.io",root:"/hexo/",scheme:"Pisces",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!0,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{appID:"0C48U14D5U",apiKey:"796da148bd60fa95ebae037cae6d5c16",indexName:"Notes",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!1,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="前言 写了两周基金申请报告也是醉了，说什么基金申请下来后我们出国交流就不用钱啦！多么拙劣的谎言，我只想中一篇论文达到毕业要求，然后去实习就行。今天又吐槽我说我晚上出勤不够，您真不愧是大学城最努力的老师。这都还没毕业，实验室的同学们都已经过上了公务员那种朝九晚五的生活。继续学习卷积神经网络，看看怎么用 Tensorflow 实现多分类问题。"><meta property="og:type" content="article"><meta property="og:title" content="卷积神经网络应用"><meta property="og:url" content="https://pengzhendong.github.io/hexo/2018/12/05/convnet-application/index.html"><meta property="og:site_name" content="Randy&#39;s Notes"><meta property="og:description" content="前言 写了两周基金申请报告也是醉了，说什么基金申请下来后我们出国交流就不用钱啦！多么拙劣的谎言，我只想中一篇论文达到毕业要求，然后去实习就行。今天又吐槽我说我晚上出勤不够，您真不愧是大学城最努力的老师。这都还没毕业，实验室的同学们都已经过上了公务员那种朝九晚五的生活。继续学习卷积神经网络，看看怎么用 Tensorflow 实现多分类问题。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://pengzhendong.github.io/hexo/2018/12/05/convnet-application/SIGNS.png"><meta property="og:image" content="https://pengzhendong.github.io/hexo/2018/12/05/convnet-application/output.png"><meta property="article:published_time" content="2018-12-05T11:16:44.000Z"><meta property="article:modified_time" content="2018-12-05T15:45:07.000Z"><meta property="article:author" content="Randy Peng"><meta property="article:tag" content="Deep Learning"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://pengzhendong.github.io/hexo/2018/12/05/convnet-application/SIGNS.png"><link rel="canonical" href="https://pengzhendong.github.io/hexo/2018/12/05/convnet-application/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><style type="text/css">body{background-image:url(/images/rockywall.png)}</style><title>卷积神经网络应用 | Randy's Notes</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-92548519-1"></script><script>if(CONFIG.hostname===location.hostname){function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-92548519-1")}</script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?06c54470f22c395ef480d6fb358497d5";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><style>mjx-container[jax=SVG]{direction:ltr}mjx-container[jax=SVG]>svg{overflow:visible}mjx-container[jax=SVG][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=SVG][justify=left]{text-align:left}mjx-container[jax=SVG][justify=right]{text-align:right}g[data-mml-node=merror]>g{fill:red;stroke:red}g[data-mml-node=merror]>rect[data-background]{fill:#ff0;stroke:none}g[data-mml-node=mtable]>line[data-line]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>rect[data-frame]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>.mjx-dashed{stroke-dasharray:140}g[data-mml-node=mtable]>.mjx-dotted{stroke-linecap:round;stroke-dasharray:0,140}g[data-mml-node=mtable]>svg{overflow:visible}[jax=SVG] mjx-tool{display:inline-block;position:relative;width:0;height:0}[jax=SVG] mjx-tool>mjx-tip{position:absolute;top:0;left:0}mjx-tool>mjx-tip{display:inline-block;padding:.2em;border:1px solid #888;font-size:70%;background-color:#f8f8f8;color:#000;box-shadow:2px 2px 5px #aaa}g[data-mml-node=maction][data-toggle]{cursor:pointer}mjx-status{display:block;position:fixed;left:1em;bottom:1em;min-width:25%;padding:.2em .4em;border:1px solid #888;font-size:90%;background-color:#f8f8f8;color:#000}foreignObject[data-mjx-xml]{font-family:initial;line-height:normal;overflow:visible}.MathJax path{stroke-width:3}mjx-container[display=true]{overflow:auto hidden}mjx-container[display=true]+br{display:none}</style></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/hexo/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">Randy's Notes</h1><span class="logo-line-after"><i></i></span></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/hexo/" rel="section"><i class="fa fa-home fa-fw"></i> 首页</a></li><li class="menu-item menu-item-archives"><a href="/hexo/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> 归档</a></li><li class="menu-item menu-item-友链"><a href="/hexo/friends/" rel="section"><i class="fa fa-users fa-fw"></i> 友链</a></li><li class="menu-item menu-item-书单"><a href="/hexo/books/" rel="section"><i class="fa fa-book fa-fw"></i> 书单</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div class="algolia-results"><div id="algolia-stats"></div><div id="algolia-hits"></div><div id="algolia-pagination" class="algolia-pagination"></div></div></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><a href="https://github.com/pengzhendong" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://pengzhendong.github.io/hexo/2018/12/05/convnet-application/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/hexo/images/avatar.jpg"><meta itemprop="name" content="Randy Peng"><meta itemprop="description" content="路漫漫其修远兮 吾将上下而求索"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Randy's Notes"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">卷积神经网络应用</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2018-12-05 11:16:44 / 修改时间：15:45:07" itemprop="dateCreated datePublished" datetime="2018-12-05T11:16:44+00:00">2018-12-05</time></span><span id="/hexo/2018/12/05/convnet-application/" class="post-meta-item leancloud_visitors" data-flag-title="卷积神经网络应用" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span class="leancloud-visitors-count"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>6.3k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>6 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="前言">前言</h2><p>写了两周基金申请报告也是醉了，说什么基金申请下来后我们出国交流就不用钱啦！多么拙劣的谎言，我只想中一篇论文达到毕业要求，然后去实习就行。今天又吐槽我说我晚上出勤不够，您真不愧是大学城最努力的老师。这都还没毕业，实验室的同学们都已经过上了公务员那种朝九晚五的生活。继续学习卷积神经网络，看看怎么用 Tensorflow 实现多分类问题。</p><span id="more"></span><h2 id="tensorflow-模型">Tensorflow 模型</h2><p>这个实验的要求是对手势进行识别，分析图片中的手势表示的是哪个数字（0~6）。手势图像如下所示：</p><p><img src="SIGNS.png"></p><p>首先载入需要用到的包和数据集，对数据进行简单的预处理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> ndimage</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> ops</span><br><span class="line"><span class="keyword">from</span> cnn_utils <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()</span><br><span class="line">X_train = X_train_orig/<span class="number">255.</span></span><br><span class="line">X_test = X_test_orig/<span class="number">255.</span></span><br><span class="line">Y_train = convert_to_one_hot(Y_train_orig, <span class="number">6</span>).T</span><br><span class="line">Y_test = convert_to_one_hot(Y_test_orig, <span class="number">6</span>).T</span><br><span class="line">conv_layers = {}</span><br></pre></td></tr></table></figure><h3 id="创建-placeholders">创建 placeholders</h3><p>需要给数据创建 placeholders，在运行 session 的时候就可以喂入数据。使用 <code>None</code> 作为 batch size，这样就可以在后面的时候比较灵活地设置小批量的大小：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_placeholders</span>(<span class="params">n_H0, n_W0, n_C0, n_y</span>):</span><br><span class="line">    X = tf.placeholder(tf.float32, [<span class="literal">None</span>, n_H0, n_W0, n_C0])</span><br><span class="line">    Y = tf.placeholder(tf.float32, [<span class="literal">None</span>, n_y])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X, Y</span><br></pre></td></tr></table></figure><h3 id="初始化参数">初始化参数</h3><p>网络为两层卷积神经网络，分别初始化每一层的权值<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.05ex" xmlns="http://www.w3.org/2000/svg" width="3.502ex" height="1.595ex" role="img" focusable="false" viewBox="0 -683 1548 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674 695 670 692 659 687 641 683 639T661 637Q636 636 621 632T600 624 597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170 666 200 690 241 720 295 759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647 817 650 819 660 823 676 825 679T839 682Q842 682 856 682T895 682 949 681Q1015 681 1034 683 1048 683 1048 672 1048 666 1045 655T1038 640 1028 637Q1006 637 988 631T958 617 939 600 927 584L923 578 754 282Q586-14 585-15 579-22 561-22 546-22 542-17 539-14 523 229T506 480L494 462Q472 425 366 239 222-13 220-15T215-19Q210-22 197-22 178-22 176-15 176-12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648 52 671 64 683H76Q118 680 176 680 301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620 262 160 266 136L501 550 499 587Q496 629 489 632 483 636 447 637 428 637 422 639T416 648Q416 650 418 660 419 664 420 669T421 676 424 680 428 682 436 683Z"></path></g><g data-mml-node="mn" transform="translate(1048,0)"><path data-c="31" d="M213 578 200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641 273 663Q275 666 285 666 294 666 302 660V361L303 61Q310 54 315 52T339 48 401 46H427V0H416Q395 3 257 3 121 3 100 0H88V46H114Q136 46 152 46T177 47 193 50 201 52 207 57 213 61V578Z"></path></g></g></g></svg></mjx-container></span>和<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.05ex" xmlns="http://www.w3.org/2000/svg" width="3.502ex" height="1.595ex" role="img" focusable="false" viewBox="0 -683 1548 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674 695 670 692 659 687 641 683 639T661 637Q636 636 621 632T600 624 597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170 666 200 690 241 720 295 759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647 817 650 819 660 823 676 825 679T839 682Q842 682 856 682T895 682 949 681Q1015 681 1034 683 1048 683 1048 672 1048 666 1045 655T1038 640 1028 637Q1006 637 988 631T958 617 939 600 927 584L923 578 754 282Q586-14 585-15 579-22 561-22 546-22 542-17 539-14 523 229T506 480L494 462Q472 425 366 239 222-13 220-15T215-19Q210-22 197-22 178-22 176-15 176-12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648 52 671 64 683H76Q118 680 176 680 301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620 262 160 266 136L501 550 499 587Q496 629 489 632 483 636 447 637 428 637 422 639T416 648Q416 650 418 660 419 664 420 669T421 676 424 680 428 682 436 683Z"></path></g><g data-mml-node="mn" transform="translate(1048,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315 301 241Q265 210 201 149L142 93 218 92Q375 92 385 97 392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19 31Q50 38 56 46T86 81Q115 113 136 137 145 147 170 174T204 211 233 244 261 278 284 308 305 340 320 369 333 401 340 431 343 464Q343 527 309 573T212 619Q179 619 154 602T119 569 109 550Q109 549 114 549 132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></svg></mjx-container></span>，也就是滤波器 。其中<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.05ex" xmlns="http://www.w3.org/2000/svg" width="3.502ex" height="1.595ex" role="img" focusable="false" viewBox="0 -683 1548 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674 695 670 692 659 687 641 683 639T661 637Q636 636 621 632T600 624 597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170 666 200 690 241 720 295 759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647 817 650 819 660 823 676 825 679T839 682Q842 682 856 682T895 682 949 681Q1015 681 1034 683 1048 683 1048 672 1048 666 1045 655T1038 640 1028 637Q1006 637 988 631T958 617 939 600 927 584L923 578 754 282Q586-14 585-15 579-22 561-22 546-22 542-17 539-14 523 229T506 480L494 462Q472 425 366 239 222-13 220-15T215-19Q210-22 197-22 178-22 176-15 176-12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648 52 671 64 683H76Q118 680 176 680 301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620 262 160 266 136L501 550 499 587Q496 629 489 632 483 636 447 637 428 637 422 639T416 648Q416 650 418 660 419 664 420 669T421 676 424 680 428 682 436 683Z"></path></g><g data-mml-node="mn" transform="translate(1048,0)"><path data-c="31" d="M213 578 200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641 273 663Q275 666 285 666 294 666 302 660V361L303 61Q310 54 315 52T339 48 401 46H427V0H416Q395 3 257 3 121 3 100 0H88V46H114Q136 46 152 46T177 47 193 50 201 52 207 57 213 61V578Z"></path></g></g></g></svg></mjx-container></span>包含 8 个大小为 4 的 3 通道滤波器，<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.05ex" xmlns="http://www.w3.org/2000/svg" width="3.502ex" height="1.595ex" role="img" focusable="false" viewBox="0 -683 1548 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674 695 670 692 659 687 641 683 639T661 637Q636 636 621 632T600 624 597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170 666 200 690 241 720 295 759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647 817 650 819 660 823 676 825 679T839 682Q842 682 856 682T895 682 949 681Q1015 681 1034 683 1048 683 1048 672 1048 666 1045 655T1038 640 1028 637Q1006 637 988 631T958 617 939 600 927 584L923 578 754 282Q586-14 585-15 579-22 561-22 546-22 542-17 539-14 523 229T506 480L494 462Q472 425 366 239 222-13 220-15T215-19Q210-22 197-22 178-22 176-15 176-12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648 52 671 64 683H76Q118 680 176 680 301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620 262 160 266 136L501 550 499 587Q496 629 489 632 483 636 447 637 428 637 422 639T416 648Q416 650 418 660 419 664 420 669T421 676 424 680 428 682 436 683Z"></path></g><g data-mml-node="mn" transform="translate(1048,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315 301 241Q265 210 201 149L142 93 218 92Q375 92 385 97 392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19 31Q50 38 56 46T86 81Q115 113 136 137 145 147 170 174T204 211 233 244 261 278 284 308 305 340 320 369 333 401 340 431 343 464Q343 527 309 573T212 619Q179 619 154 602T119 569 109 550Q109 549 114 549 132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></svg></mjx-container></span>包含 16 个大小为 2 的 8 通道滤波器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize_parameters</span>():</span><br><span class="line">    tf.set_random_seed(<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    W1 = tf.get_variable(<span class="string">"W1"</span>, [<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">8</span>], initializer=tf.contrib.layers.xavier_initializer(seed=<span class="number">0</span>))</span><br><span class="line">    W2 = tf.get_variable(<span class="string">"W2"</span>, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">16</span>], initializer=tf.contrib.layers.xavier_initializer(seed=<span class="number">0</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> {<span class="string">"W1"</span>: W1, <span class="string">"W2"</span>: W2}</span><br></pre></td></tr></table></figure><h3 id="前向传播">前向传播</h3><p>在 Tensorflow 中，提供了以下函数可以用来快速构建卷积神经网络：</p><ul><li><code>tf.nn.conv2d(X, W1, strides=[1,s,s,1], padding='SAME')</code>：给定输入<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:0" xmlns="http://www.w3.org/2000/svg" width="1.928ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 852 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44B" d="M42 0H40Q26 0 26 11 26 15 29 27 33 41 36 43T55 46Q141 49 190 98 200 108 306 224T411 342Q302 620 297 625 288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681 380 681 408 681T453 682 473 682Q490 682 490 671 490 670 488 658 484 643 481 640T465 637Q434 634 411 620L488 426 541 485Q646 598 646 610 646 628 622 635 617 635 609 637 594 637 594 648 594 650 596 664 600 677 606 683H618Q619 683 643 683T697 681 738 680Q828 680 837 683H845Q852 676 852 672 850 647 840 637H824Q790 636 763 628T722 611 698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142 638 56Q648 47 699 46 734 46 734 37 734 35 732 23 728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10 444 11 446 25 448 35 450 39T455 44 464 46 480 47 506 54Q523 62 523 64 522 64 476 181L429 299Q241 95 236 84 232 76 232 72 232 53 261 47 262 47 267 47T273 46Q276 46 277 46T280 45 283 42 284 35Q284 26 282 19 279 6 276 4T261 1Q258 1 243 1T201 2 142 2Q64 2 42 0Z"></path></g></g></g></svg></mjx-container></span>和一组滤波器<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.05ex" xmlns="http://www.w3.org/2000/svg" width="3.502ex" height="1.595ex" role="img" focusable="false" viewBox="0 -683 1548 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674 695 670 692 659 687 641 683 639T661 637Q636 636 621 632T600 624 597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170 666 200 690 241 720 295 759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647 817 650 819 660 823 676 825 679T839 682Q842 682 856 682T895 682 949 681Q1015 681 1034 683 1048 683 1048 672 1048 666 1045 655T1038 640 1028 637Q1006 637 988 631T958 617 939 600 927 584L923 578 754 282Q586-14 585-15 579-22 561-22 546-22 542-17 539-14 523 229T506 480L494 462Q472 425 366 239 222-13 220-15T215-19Q210-22 197-22 178-22 176-15 176-12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648 52 671 64 683H76Q118 680 176 680 301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620 262 160 266 136L501 550 499 587Q496 629 489 632 483 636 447 637 428 637 422 639T416 648Q416 650 418 660 419 664 420 669T421 676 424 680 428 682 436 683Z"></path></g><g data-mml-node="mn" transform="translate(1048,0)"><path data-c="31" d="M213 578 200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641 273 663Q275 666 285 666 294 666 302 660V361L303 61Q310 54 315 52T339 48 401 46H427V0H416Q395 3 257 3 121 3 100 0H88V46H114Q136 46 152 46T177 47 193 50 201 52 207 57 213 61V578Z"></path></g></g></g></svg></mjx-container></span>，该函数回使用<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.05ex" xmlns="http://www.w3.org/2000/svg" width="3.502ex" height="1.595ex" role="img" focusable="false" viewBox="0 -683 1548 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674 695 670 692 659 687 641 683 639T661 637Q636 636 621 632T600 624 597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170 666 200 690 241 720 295 759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647 817 650 819 660 823 676 825 679T839 682Q842 682 856 682T895 682 949 681Q1015 681 1034 683 1048 683 1048 672 1048 666 1045 655T1038 640 1028 637Q1006 637 988 631T958 617 939 600 927 584L923 578 754 282Q586-14 585-15 579-22 561-22 546-22 542-17 539-14 523 229T506 480L494 462Q472 425 366 239 222-13 220-15T215-19Q210-22 197-22 178-22 176-15 176-12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648 52 671 64 683H76Q118 680 176 680 301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620 262 160 266 136L501 550 499 587Q496 629 489 632 483 636 447 637 428 637 422 639T416 648Q416 650 418 660 419 664 420 669T421 676 424 680 428 682 436 683Z"></path></g><g data-mml-node="mn" transform="translate(1048,0)"><path data-c="31" d="M213 578 200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641 273 663Q275 666 285 666 294 666 302 660V361L303 61Q310 54 315 52T339 48 401 46H427V0H416Q395 3 257 3 121 3 100 0H88V46H114Q136 46 152 46T177 47 193 50 201 52 207 57 213 61V578Z"></path></g></g></g></svg></mjx-container></span>中的滤波器和<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:0" xmlns="http://www.w3.org/2000/svg" width="1.928ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 852 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44B" d="M42 0H40Q26 0 26 11 26 15 29 27 33 41 36 43T55 46Q141 49 190 98 200 108 306 224T411 342Q302 620 297 625 288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681 380 681 408 681T453 682 473 682Q490 682 490 671 490 670 488 658 484 643 481 640T465 637Q434 634 411 620L488 426 541 485Q646 598 646 610 646 628 622 635 617 635 609 637 594 637 594 648 594 650 596 664 600 677 606 683H618Q619 683 643 683T697 681 738 680Q828 680 837 683H845Q852 676 852 672 850 647 840 637H824Q790 636 763 628T722 611 698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142 638 56Q648 47 699 46 734 46 734 37 734 35 732 23 728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10 444 11 446 25 448 35 450 39T455 44 464 46 480 47 506 54Q523 62 523 64 522 64 476 181L429 299Q241 95 236 84 232 76 232 72 232 53 261 47 262 47 267 47T273 46Q276 46 277 46T280 45 283 42 284 35Q284 26 282 19 279 6 276 4T261 1Q258 1 243 1T201 2 142 2Q64 2 42 0Z"></path></g></g></g></svg></mjx-container></span>进行卷积运算，第三个参数指定了<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:0" xmlns="http://www.w3.org/2000/svg" width="1.928ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 852 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44B" d="M42 0H40Q26 0 26 11 26 15 29 27 33 41 36 43T55 46Q141 49 190 98 200 108 306 224T411 342Q302 620 297 625 288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681 380 681 408 681T453 682 473 682Q490 682 490 671 490 670 488 658 484 643 481 640T465 637Q434 634 411 620L488 426 541 485Q646 598 646 610 646 628 622 635 617 635 609 637 594 637 594 648 594 650 596 664 600 677 606 683H618Q619 683 643 683T697 681 738 680Q828 680 837 683H845Q852 676 852 672 850 647 840 637H824Q790 636 763 628T722 611 698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142 638 56Q648 47 699 46 734 46 734 37 734 35 732 23 728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10 444 11 446 25 448 35 450 39T455 44 464 46 480 47 506 54Q523 62 523 64 522 64 476 181L429 299Q241 95 236 84 232 76 232 72 232 53 261 47 262 47 267 47T273 46Q276 46 277 46T280 45 283 42 284 35Q284 26 282 19 279 6 276 4T261 1Q258 1 243 1T201 2 142 2Q64 2 42 0Z"></path></g></g></g></svg></mjx-container></span>每个维度的卷积步长。</li><li><code>tf.nn.max_pool(A, ksize=[1,f,f,1], strides=[1,s,s,1], padding='SAME')</code>：给定输入 A，滤波器大小为 f，使用最大池化进行运算。</li><li><code>tf.nn.relu(Z1)</code>：对 Z1 中的每个元素进行 ReLU 运算。</li><li><code>tf.contrib.layers.flatten(P)</code>：给定输入 P，将其变平（flatten）成一维向量。如果 P 中包含 batch-size 则变成形状为 [batch_size, k] 的张量。</li><li><code>tf.contrib.layers.fully_connected(F, num_outputs)</code>：给定变平的输入，返回全连接神经网络层计算的输出，该层自动初始化权值。</li></ul><p>卷积神经网络的前向传播主要流程为：<code>CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED</code>，每一层的参数配置如下所示：</p><ol type="1"><li>Conv2D：步长为 1，零填充为 SAME 卷积；</li><li>ReLU；</li><li>Max pool：滤波器大小为 8，步长为 8；</li><li>Conv2D：卷积步长为 1，零填充为 SAME 卷积；</li><li>ReLU；</li><li>Max pool：滤波器尺大小为 4，步长为 4</li><li>将前面的输出变平（flatten）；</li><li>FULLYCONNECTED (全连接) 层：此处不需要使用 softmax 函数，在 Tensorflow 中，softmax 和代价函数被写成了一个单独的函数，所以可以直接在全连接层的输出上计算代价。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_propagation</span>(<span class="params">X, parameters</span>):</span><br><span class="line">    <span class="comment"># Retrieve the parameters from the dictionary "parameters" </span></span><br><span class="line">    W1 = parameters[<span class="string">'W1'</span>]</span><br><span class="line">    W2 = parameters[<span class="string">'W2'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># CONV2D: stride of 1, padding 'SAME'</span></span><br><span class="line">    Z1 = tf.nn.conv2d(X, W1, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    <span class="comment"># RELU</span></span><br><span class="line">    A1 = tf.nn.relu(Z1)</span><br><span class="line">    <span class="comment"># MAXPOOL: window 8x8, stride 8, padding 'SAME'</span></span><br><span class="line">    P1 = tf.nn.max_pool(A1, ksize = [<span class="number">1</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>], strides = [<span class="number">1</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    <span class="comment"># CONV2D: filters W2, stride 1, padding 'SAME'</span></span><br><span class="line">    Z2 = tf.nn.conv2d(P1, W2, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    <span class="comment"># RELU</span></span><br><span class="line">    A2 = tf.nn.relu(Z2)</span><br><span class="line">    <span class="comment"># MAXPOOL: window 4x4, stride 4, padding 'SAME'</span></span><br><span class="line">    P2 = tf.nn.max_pool(A2, ksize = [<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>], strides = [<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    <span class="comment"># FLATTEN</span></span><br><span class="line">    P = tf.contrib.layers.flatten(P2)</span><br><span class="line">    <span class="comment"># FULLY-CONNECTED without non-linear activation function (not not call softmax).</span></span><br><span class="line">    <span class="comment"># 6 neurons in output layer. Hint: one of the arguments should be "activation_fn=None" </span></span><br><span class="line">    Z3 = tf.contrib.layers.fully_connected(P, <span class="number">6</span>, activation_fn=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Z3</span><br></pre></td></tr></table></figure><h3 id="计算代价">计算代价</h3><ul><li><code>tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y)</code>：计算 softmax 交叉损失，该函数包含了 softmax 函数。</li><li><code>tf.reduce_mean</code>：计算张量每个维度的均值，用来计算整体的代价。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_cost</span>(<span class="params">Z3, Y</span>):</span><br><span class="line">    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure><h3 id="模型">模型</h3><p>整体的模型包含以上几个步骤，最后需要创建优化器，然后运行 session 迭代数据集 num_epochs 次，在每个最小批量上运行优化器。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">model</span>(<span class="params">X_train, Y_train, X_test, Y_test, learning_rate=<span class="number">0.009</span>,</span></span><br><span class="line"><span class="params">          num_epochs=<span class="number">100</span>, minibatch_size=<span class="number">64</span>, print_cost=<span class="literal">True</span></span>):</span><br><span class="line">    ops.reset_default_graph()                         <span class="comment"># to be able to rerun the model without overwriting tf variables</span></span><br><span class="line">    tf.set_random_seed(<span class="number">1</span>)                             <span class="comment"># to keep results consistent (tensorflow seed)</span></span><br><span class="line">    seed = <span class="number">3</span>                                          <span class="comment"># to keep results consistent (numpy seed)</span></span><br><span class="line">    (m, n_H0, n_W0, n_C0) = X_train.shape             </span><br><span class="line">    n_y = Y_train.shape[<span class="number">1</span>]                            </span><br><span class="line">    costs = []                                        <span class="comment"># To keep track of the cost</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create Placeholders of the correct shape</span></span><br><span class="line">    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize parameters</span></span><br><span class="line">    parameters = initialize_parameters()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Forward propagation: Build the forward propagation in the tensorflow graph</span></span><br><span class="line">    Z3 = forward_propagation(X, parameters)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Cost function: Add cost function to tensorflow graph</span></span><br><span class="line">    cost = compute_cost(Z3, Y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.</span></span><br><span class="line">    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize all the variables globally</span></span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line">     </span><br><span class="line">    <span class="comment"># Start the session to compute the tensorflow graph</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Run the initialization</span></span><br><span class="line">        sess.run(init)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Do the training loop</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line"></span><br><span class="line">            minibatch_cost = <span class="number">0.</span></span><br><span class="line">            num_minibatches = <span class="built_in">int</span>(m / minibatch_size) <span class="comment"># number of minibatches of size minibatch_size in the train set</span></span><br><span class="line">            seed = seed + <span class="number">1</span></span><br><span class="line">            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> minibatch <span class="keyword">in</span> minibatches:</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Select a minibatch</span></span><br><span class="line">                (minibatch_X, minibatch_Y) = minibatch</span><br><span class="line">                <span class="comment"># IMPORTANT: The line that runs the graph on a minibatch.</span></span><br><span class="line">                <span class="comment"># Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).</span></span><br><span class="line">                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})</span><br><span class="line">                </span><br><span class="line">                minibatch_cost += temp_cost / num_minibatches</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># Print the cost every epoch</span></span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="literal">True</span> <span class="keyword">and</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span> (<span class="string">"Cost after epoch %i: %f"</span> % (epoch, minibatch_cost))</span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="literal">True</span> <span class="keyword">and</span> epoch % <span class="number">1</span> == <span class="number">0</span>:</span><br><span class="line">                costs.append(minibatch_cost)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># plot the cost</span></span><br><span class="line">        plt.plot(np.squeeze(costs))</span><br><span class="line">        plt.ylabel(<span class="string">'cost'</span>)</span><br><span class="line">        plt.xlabel(<span class="string">'iterations (per tens)'</span>)</span><br><span class="line">        plt.title(<span class="string">"Learning rate ="</span> + <span class="built_in">str</span>(learning_rate))</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the correct predictions</span></span><br><span class="line">        predict_op = tf.argmax(Z3, <span class="number">1</span>)</span><br><span class="line">        correct_prediction = tf.equal(predict_op, tf.argmax(Y, <span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Calculate accuracy on the test set</span></span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line">        <span class="built_in">print</span>(accuracy)</span><br><span class="line">        train_accuracy = accuracy.<span class="built_in">eval</span>({X: X_train, Y: Y_train})</span><br><span class="line">        test_accuracy = accuracy.<span class="built_in">eval</span>({X: X_test, Y: Y_test})</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"Train Accuracy:"</span>, train_accuracy)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"Test Accuracy:"</span>, test_accuracy)</span><br><span class="line">                </span><br><span class="line">        <span class="keyword">return</span> train_accuracy, test_accuracy, parameters</span><br></pre></td></tr></table></figure><p>运行以下代码，将模型训练 100 个 epoch，同时每 5 个 epoch 输出模型的代价：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">_, _, parameters = model(X_train, Y_train, X_test, Y_test)</span><br></pre></td></tr></table></figure><p><img src="output.png"></p><p>最后模型在训练集上的准确度能达到 94%，在测试集上能达到 78%。模型的方差比较高，还可以继续调节超参数和使用正则项提高模型的性能。</p><h2 id="总结">总结</h2><p>投出去的论文的实验也是用 Tensorflow 实现的，Tensorflow 确实强大，但是如果不是很熟悉就想用还是有点难，当时遇到一些小问题都得花半天时间解决，看来还需要多学习一下，多看看文档。</p><h2 id="参考文献">参考文献</h2><ol type="1"><li>吴恩达. DeepLearning.</li></ol></div><div class="reward-container"><div>疏影横斜水清浅，暗香浮动月黄昏</div><button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'>打赏</button><div id="qr" style="display:none"><div style="display:inline-block"><img src="/hexo/images/wechatpay.png" alt="Randy Peng 微信支付"><p>微信支付</p></div><div style="display:inline-block"><img src="/hexo/images/alipay.png" alt="Randy Peng 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong> Randy Peng</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://pengzhendong.github.io/hexo/2018/12/05/convnet-application/" title="卷积神经网络应用">https://pengzhendong.github.io/hexo/2018/12/05/convnet-application/</a></li><li class="post-copyright-license"><strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><center><br><div class="addthis_inline_share_toolbox"><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5aa9d6309315fb5e" async="async"></script></div></center><footer class="post-footer"><div class="post-tags"><a href="/hexo/tags/Deep-Learning/" rel="tag"># Deep Learning</a></div><div class="post-nav"><div class="post-nav-item"><a href="/hexo/2018/12/03/convolutional-neural-networks/" rel="prev" title="卷积神经网络"><i class="fa fa-chevron-left"></i> 卷积神经网络</a></div><div class="post-nav-item"><a href="/hexo/2018/12/10/deep-convnet-probe/" rel="next" title="深度卷积网络探究">深度卷积网络探究<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><script>window.addEventListener("tabs:register",()=>{let{activeClass:t}=CONFIG.comments;if(CONFIG.comments.storage&&(t=localStorage.getItem("comments_active")||t),t){let e=document.querySelector(`a[href="#comment-${t}"]`);e&&e.click()}}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{if(!t.target.matches(".tabs-comment .tab-content .tab-pane"))return;let e=t.target.classList[1];localStorage.setItem("comments_active",e)})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tensorflow-%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.</span> <span class="nav-text">Tensorflow 模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA-placeholders"><span class="nav-number">2.1.</span> <span class="nav-text">创建 placeholders</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%82%E6%95%B0"><span class="nav-number">2.2.</span> <span class="nav-text">初始化参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="nav-number">2.3.</span> <span class="nav-text">前向传播</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E4%BB%A3%E4%BB%B7"><span class="nav-number">2.4.</span> <span class="nav-text">计算代价</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.5.</span> <span class="nav-text">模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">3.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number">4.</span> <span class="nav-text">参考文献</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Randy Peng" src="/hexo/images/avatar.jpg"><p class="site-author-name" itemprop="name">Randy Peng</p><div class="site-description" itemprop="description">路漫漫其修远兮 吾将上下而求索</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/hexo/archives/"><span class="site-state-item-count">35</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-tags"><a href="/hexo/tags/"><span class="site-state-item-count">7</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/pengzhendong" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;pengzhendong" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="https://twitter.com/pengzhendong" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;pengzhendong" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i> Twitter</a></span><span class="links-of-author-item"><a href="mailto:275331498@qq.com" title="E-Mail → mailto:275331498@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span><span class="links-of-author-item"><a href="https://www.facebook.com/pengzhendong" title="FaceBook → https:&#x2F;&#x2F;www.facebook.com&#x2F;pengzhendong" rel="noopener" target="_blank"><i class="fab fa-facebook fa-fw"></i> FaceBook</a></span><span class="links-of-author-item"><a href="https://t.me/pengzhendong" title="Telegram → https:&#x2F;&#x2F;t.me&#x2F;pengzhendong" rel="noopener" target="_blank"><i class="fab fa-telegram fa-fw"></i> Telegram</a></span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/pengzhendong" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;pengzhendong" rel="noopener" target="_blank"><i class="fab fa-leanpub fa-fw"></i> 知乎</a></span><span class="links-of-author-item"><a href="https://weibo.com/qq275331498" title="微博 → https:&#x2F;&#x2F;weibo.com&#x2F;qq275331498" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i> 微博</a></span><span class="links-of-author-item"><a href="/hexo/about" title="关于 → &#x2F;about"><i class="fa fa-user fa-fw"></i> 关于</a></span></div><hr style="margin-top:20px;margin-bottom:20px"><img src="/images/wechat.png"></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; 2015 – <span itemprop="copyrightYear">2022</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">Randy Peng</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-chart-area"></i></span> <span title="站点总字数">230k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span title="站点阅读时长">3:29</span></div><script>!function(){function e(e){return e=encodeURI(e),document.getElementById(e).querySelector(".leancloud-visitors-count")}let{app_id:t,app_key:o,server_url:n}={enable:!0,app_id:"YHMwvrTgcfDjOXmiGY3jQ2r5-gzGzoHsz",app_key:"JRfKfM8mRPgxMB9GOSAnix9W",server_url:null,security:!0};function r(n){var r=(e,r,l)=>fetch(`${n}/1.1${r}`,{method:e,headers:{"X-LC-Id":t,"X-LC-Key":o,"Content-Type":"application/json"},body:JSON.stringify(l)});if(CONFIG.page.isPost){if(CONFIG.hostname!==location.hostname)return;!function(t){var o=document.querySelector(".leancloud_visitors"),n=decodeURI(o.id);o.dataset.flagTitle,t("get","/classes/Counter?where="+encodeURIComponent(JSON.stringify({url:n}))).then(e=>e.json()).then(({results:o})=>{if(o.length>0){var r=o[0];e(n).innerText=r.time+1,t("put","/classes/Counter/"+r.objectId,{time:{__op:"Increment",amount:1}}).catch(e=>{console.error("Failed to save visitor count",e)})}else e(n).innerText="Counter not initialized! More info at console err msg.",console.error("ATTENTION! LeanCloud counter has security bug, see how to solve it here: https://github.com/theme-next/hexo-leancloud-counter-security. \n However, you can still use LeanCloud without security, by setting `security` option to `false`.")}).catch(e=>{console.error("LeanCloud Counter Error",e)})}(r)}else document.querySelectorAll(".post-title-link").length>=1&&function(t){var o=[...document.querySelectorAll(".leancloud_visitors")].map(e=>decodeURI(e.id));t("get","/classes/Counter?where="+encodeURIComponent(JSON.stringify({url:{$in:o}}))).then(e=>e.json()).then(({results:t})=>{for(let n of o){let o=t.find(e=>e.url===n);e(n).innerText=o?o.time:0}}).catch(e=>{console.error("LeanCloud Counter Error",e)})}(r)}let l="-MdYXbMMI"!==t.slice(-9)?n:`https://${t.slice(0,8).toLowerCase()}.api.lncldglobal.com`;l?r(l):fetch("https://app-router.leancloud.cn/2/route?appId="+t).then(e=>e.json()).then(({api_server:e})=>{r("https://"+e)})}()</script></div></footer></div><script src="/hexo/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script><script src="/hexo/lib/velocity/velocity.min.js"></script><script src="/hexo/lib/velocity/velocity.ui.min.js"></script><script src="/hexo/js/utils.js"></script><script src="/hexo/js/motion.js"></script><script src="/hexo/js/schemes/pisces.js"></script><script src="/hexo/js/next-boot.js"></script><script>!function(){var e,t,o=document.getElementsByTagName("link");if(o.length>0)for(i=0;i<o.length;i++)"canonical"==o[i].rel.toLowerCase()&&o[i].href&&(e=o[i].href);t=e?e.split(":")[0]:window.location.protocol.split(":")[0],e||(e=window.location.href),function(){var i=e,o=document.referrer;if(!/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(i)){var n="https"===String(t).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),i&&(n+="&l="+i)):i&&(n+="?l="+i),(new Image).src=n}}(window)}()</script><script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script><script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script><script src="/hexo/js/algolia-search.js"></script><script>"undefined"==typeof MathJax?(window.MathJax={loader:{source:{"[tex]/amsCd":"[tex]/amscd","[tex]/AMScd":"[tex]/amscd"}},tex:{inlineMath:{"[+]":[["$","$"]]},tags:"ams"},options:{renderActions:{findScript:[10,e=>{document.querySelectorAll('script[type^="math/tex"]').forEach(t=>{const a=!!t.type.match(/; *mode=display/),n=new e.options.MathItem(t.textContent,e.inputJax[0],a),d=document.createTextNode("");t.parentNode.replaceChild(d,t),n.start={node:d,delim:"",n:0},n.end={node:d,delim:"",n:0},e.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}},function(){var e=document.createElement("script");e.src="//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js",e.defer=!0,document.head.appendChild(e)}()):(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset())</script></body></html>